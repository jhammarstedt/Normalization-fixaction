{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "505a1ae5edcfd2fe8fb60b2c502a0fe59d741830bbe3a9bda8b3a262b5475b51"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "bcancer_data_understanding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyFV76OOGGIl"
      },
      "source": [
        "from normal_methods import z_score, Normalizator\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "U0EXbCzpGGIm",
        "outputId": "6025fb8a-7923-438c-d7c0-7cad1306272c"
      },
      "source": [
        "ds = Normalizator(dataset=\"breastCancer\")\n",
        "ds.df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>radius_1</th>\n",
              "      <th>texture_1</th>\n",
              "      <th>perimeter_1</th>\n",
              "      <th>area_1</th>\n",
              "      <th>smoothness_1</th>\n",
              "      <th>compactness_1</th>\n",
              "      <th>concavity_1</th>\n",
              "      <th>concave_points_1</th>\n",
              "      <th>symmetry_1</th>\n",
              "      <th>fractal_dimension_1</th>\n",
              "      <th>radius_2</th>\n",
              "      <th>texture_2</th>\n",
              "      <th>perimeter_2</th>\n",
              "      <th>area_2</th>\n",
              "      <th>smoothness_2</th>\n",
              "      <th>compactness_2</th>\n",
              "      <th>concavity_2</th>\n",
              "      <th>concave_points_2</th>\n",
              "      <th>symmetry_2</th>\n",
              "      <th>fractal_dimension_2</th>\n",
              "      <th>radius_3</th>\n",
              "      <th>texture_3</th>\n",
              "      <th>perimeter_3</th>\n",
              "      <th>area_3</th>\n",
              "      <th>smoothness_3</th>\n",
              "      <th>compactness_3</th>\n",
              "      <th>concavity_3</th>\n",
              "      <th>concave_points_3</th>\n",
              "      <th>symmetry_3</th>\n",
              "      <th>fractal_dimension_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID    radius_1  ...  symmetry_3  fractal_dimension_3\n",
              "count  5.690000e+02  569.000000  ...  569.000000           569.000000\n",
              "mean   3.037183e+07   14.127292  ...    0.290076             0.083946\n",
              "std    1.250206e+08    3.524049  ...    0.061867             0.018061\n",
              "min    8.670000e+03    6.981000  ...    0.156500             0.055040\n",
              "25%    8.692180e+05   11.700000  ...    0.250400             0.071460\n",
              "50%    9.060240e+05   13.370000  ...    0.282200             0.080040\n",
              "75%    8.813129e+06   15.780000  ...    0.317900             0.092080\n",
              "max    9.113205e+08   28.110000  ...    0.663800             0.207500\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "QzUKHyDnGGIo",
        "outputId": "0c1e5ad0-f800-4ff4-b77f-21c3235669a4"
      },
      "source": [
        "ds.normalize('tanh', reset=True)\n",
        "ds.df_norm.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>radius_1</th>\n",
              "      <th>texture_1</th>\n",
              "      <th>perimeter_1</th>\n",
              "      <th>area_1</th>\n",
              "      <th>smoothness_1</th>\n",
              "      <th>compactness_1</th>\n",
              "      <th>concavity_1</th>\n",
              "      <th>concave_points_1</th>\n",
              "      <th>symmetry_1</th>\n",
              "      <th>fractal_dimension_1</th>\n",
              "      <th>radius_2</th>\n",
              "      <th>texture_2</th>\n",
              "      <th>perimeter_2</th>\n",
              "      <th>area_2</th>\n",
              "      <th>smoothness_2</th>\n",
              "      <th>compactness_2</th>\n",
              "      <th>concavity_2</th>\n",
              "      <th>concave_points_2</th>\n",
              "      <th>symmetry_2</th>\n",
              "      <th>fractal_dimension_2</th>\n",
              "      <th>radius_3</th>\n",
              "      <th>texture_3</th>\n",
              "      <th>perimeter_3</th>\n",
              "      <th>area_3</th>\n",
              "      <th>smoothness_3</th>\n",
              "      <th>compactness_3</th>\n",
              "      <th>concavity_3</th>\n",
              "      <th>concave_points_3</th>\n",
              "      <th>symmetry_3</th>\n",
              "      <th>fractal_dimension_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.004997</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005001</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.004996</td>\n",
              "      <td>0.005002</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.004996</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005004</td>\n",
              "      <td>0.005003</td>\n",
              "      <td>0.005003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.498785</td>\n",
              "      <td>0.489853</td>\n",
              "      <td>0.488856</td>\n",
              "      <td>0.490079</td>\n",
              "      <td>0.492728</td>\n",
              "      <td>0.484445</td>\n",
              "      <td>0.491950</td>\n",
              "      <td>0.494426</td>\n",
              "      <td>0.493691</td>\n",
              "      <td>0.486283</td>\n",
              "      <td>0.490902</td>\n",
              "      <td>0.494701</td>\n",
              "      <td>0.492229</td>\n",
              "      <td>0.494780</td>\n",
              "      <td>0.496311</td>\n",
              "      <td>0.491121</td>\n",
              "      <td>0.493510</td>\n",
              "      <td>0.494713</td>\n",
              "      <td>0.490434</td>\n",
              "      <td>0.492336</td>\n",
              "      <td>0.494515</td>\n",
              "      <td>0.491366</td>\n",
              "      <td>0.488882</td>\n",
              "      <td>0.491534</td>\n",
              "      <td>0.493888</td>\n",
              "      <td>0.486590</td>\n",
              "      <td>0.492781</td>\n",
              "      <td>0.493471</td>\n",
              "      <td>0.491276</td>\n",
              "      <td>0.489197</td>\n",
              "      <td>0.491991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.498819</td>\n",
              "      <td>0.496553</td>\n",
              "      <td>0.496370</td>\n",
              "      <td>0.496540</td>\n",
              "      <td>0.496664</td>\n",
              "      <td>0.496445</td>\n",
              "      <td>0.496265</td>\n",
              "      <td>0.496281</td>\n",
              "      <td>0.496310</td>\n",
              "      <td>0.496484</td>\n",
              "      <td>0.496387</td>\n",
              "      <td>0.496882</td>\n",
              "      <td>0.496526</td>\n",
              "      <td>0.496881</td>\n",
              "      <td>0.497526</td>\n",
              "      <td>0.496880</td>\n",
              "      <td>0.496535</td>\n",
              "      <td>0.497214</td>\n",
              "      <td>0.496628</td>\n",
              "      <td>0.496742</td>\n",
              "      <td>0.497074</td>\n",
              "      <td>0.496625</td>\n",
              "      <td>0.496257</td>\n",
              "      <td>0.496552</td>\n",
              "      <td>0.496789</td>\n",
              "      <td>0.496544</td>\n",
              "      <td>0.496595</td>\n",
              "      <td>0.496218</td>\n",
              "      <td>0.496218</td>\n",
              "      <td>0.496791</td>\n",
              "      <td>0.496540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.498821</td>\n",
              "      <td>0.498925</td>\n",
              "      <td>0.499477</td>\n",
              "      <td>0.498820</td>\n",
              "      <td>0.498524</td>\n",
              "      <td>0.499826</td>\n",
              "      <td>0.498890</td>\n",
              "      <td>0.498289</td>\n",
              "      <td>0.498011</td>\n",
              "      <td>0.499642</td>\n",
              "      <td>0.499109</td>\n",
              "      <td>0.498539</td>\n",
              "      <td>0.499013</td>\n",
              "      <td>0.498567</td>\n",
              "      <td>0.498261</td>\n",
              "      <td>0.498898</td>\n",
              "      <td>0.498595</td>\n",
              "      <td>0.499005</td>\n",
              "      <td>0.499298</td>\n",
              "      <td>0.498903</td>\n",
              "      <td>0.498850</td>\n",
              "      <td>0.498655</td>\n",
              "      <td>0.499782</td>\n",
              "      <td>0.498570</td>\n",
              "      <td>0.498294</td>\n",
              "      <td>0.499766</td>\n",
              "      <td>0.498652</td>\n",
              "      <td>0.498909</td>\n",
              "      <td>0.498883</td>\n",
              "      <td>0.499363</td>\n",
              "      <td>0.498918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.499137</td>\n",
              "      <td>0.502347</td>\n",
              "      <td>0.502921</td>\n",
              "      <td>0.502498</td>\n",
              "      <td>0.501818</td>\n",
              "      <td>0.503181</td>\n",
              "      <td>0.502469</td>\n",
              "      <td>0.502630</td>\n",
              "      <td>0.503235</td>\n",
              "      <td>0.502654</td>\n",
              "      <td>0.502355</td>\n",
              "      <td>0.501330</td>\n",
              "      <td>0.502333</td>\n",
              "      <td>0.501215</td>\n",
              "      <td>0.500534</td>\n",
              "      <td>0.501842</td>\n",
              "      <td>0.501948</td>\n",
              "      <td>0.501684</td>\n",
              "      <td>0.502363</td>\n",
              "      <td>0.501778</td>\n",
              "      <td>0.501443</td>\n",
              "      <td>0.502610</td>\n",
              "      <td>0.503292</td>\n",
              "      <td>0.502701</td>\n",
              "      <td>0.501788</td>\n",
              "      <td>0.502988</td>\n",
              "      <td>0.502698</td>\n",
              "      <td>0.502656</td>\n",
              "      <td>0.503562</td>\n",
              "      <td>0.502251</td>\n",
              "      <td>0.502254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.535205</td>\n",
              "      <td>0.519846</td>\n",
              "      <td>0.523243</td>\n",
              "      <td>0.519870</td>\n",
              "      <td>0.526229</td>\n",
              "      <td>0.523836</td>\n",
              "      <td>0.522826</td>\n",
              "      <td>0.521205</td>\n",
              "      <td>0.519630</td>\n",
              "      <td>0.522409</td>\n",
              "      <td>0.524535</td>\n",
              "      <td>0.544417</td>\n",
              "      <td>0.533227</td>\n",
              "      <td>0.547169</td>\n",
              "      <td>0.554986</td>\n",
              "      <td>0.540064</td>\n",
              "      <td>0.530679</td>\n",
              "      <td>0.560072</td>\n",
              "      <td>0.533199</td>\n",
              "      <td>0.535301</td>\n",
              "      <td>0.549099</td>\n",
              "      <td>0.520460</td>\n",
              "      <td>0.519420</td>\n",
              "      <td>0.521424</td>\n",
              "      <td>0.529616</td>\n",
              "      <td>0.519767</td>\n",
              "      <td>0.525542</td>\n",
              "      <td>0.523486</td>\n",
              "      <td>0.513426</td>\n",
              "      <td>0.530193</td>\n",
              "      <td>0.534181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID    radius_1  ...  symmetry_3  fractal_dimension_3\n",
              "count  569.000000  569.000000  ...  569.000000           569.000000\n",
              "mean     0.499999    0.500000  ...    0.500000             0.500000\n",
              "std      0.004997    0.005004  ...    0.005003             0.005003\n",
              "min      0.498785    0.489853  ...    0.489197             0.491991\n",
              "25%      0.498819    0.496553  ...    0.496791             0.496540\n",
              "50%      0.498821    0.498925  ...    0.499363             0.498918\n",
              "75%      0.499137    0.502347  ...    0.502251             0.502254\n",
              "max      0.535205    0.519846  ...    0.530193             0.534181\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "KZ8Hqe76GGIo",
        "outputId": "e9287cdc-19f2-4fc3-84ed-0535e98eee6a"
      },
      "source": [
        "ds.normalize('pareto', reset=True)\n",
        "ds.df_norm.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>radius_1</th>\n",
              "      <th>texture_1</th>\n",
              "      <th>perimeter_1</th>\n",
              "      <th>area_1</th>\n",
              "      <th>smoothness_1</th>\n",
              "      <th>compactness_1</th>\n",
              "      <th>concavity_1</th>\n",
              "      <th>concave_points_1</th>\n",
              "      <th>symmetry_1</th>\n",
              "      <th>fractal_dimension_1</th>\n",
              "      <th>radius_2</th>\n",
              "      <th>texture_2</th>\n",
              "      <th>perimeter_2</th>\n",
              "      <th>area_2</th>\n",
              "      <th>smoothness_2</th>\n",
              "      <th>compactness_2</th>\n",
              "      <th>concavity_2</th>\n",
              "      <th>concave_points_2</th>\n",
              "      <th>symmetry_2</th>\n",
              "      <th>fractal_dimension_2</th>\n",
              "      <th>radius_3</th>\n",
              "      <th>texture_3</th>\n",
              "      <th>perimeter_3</th>\n",
              "      <th>area_3</th>\n",
              "      <th>smoothness_3</th>\n",
              "      <th>compactness_3</th>\n",
              "      <th>concavity_3</th>\n",
              "      <th>concave_points_3</th>\n",
              "      <th>symmetry_3</th>\n",
              "      <th>fractal_dimension_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.272761e-14</td>\n",
              "      <td>-5.894914e-15</td>\n",
              "      <td>-1.364891e-14</td>\n",
              "      <td>-3.640127e-15</td>\n",
              "      <td>-1.677081e-14</td>\n",
              "      <td>7.187182e-16</td>\n",
              "      <td>-2.659462e-16</td>\n",
              "      <td>-7.697416e-17</td>\n",
              "      <td>1.963866e-16</td>\n",
              "      <td>-3.058479e-16</td>\n",
              "      <td>3.703589e-17</td>\n",
              "      <td>-5.609773e-16</td>\n",
              "      <td>-6.785238e-16</td>\n",
              "      <td>2.434540e-15</td>\n",
              "      <td>-5.277559e-15</td>\n",
              "      <td>-3.996571e-17</td>\n",
              "      <td>-4.887713e-17</td>\n",
              "      <td>1.823868e-16</td>\n",
              "      <td>-2.209715e-17</td>\n",
              "      <td>-3.063357e-17</td>\n",
              "      <td>2.926774e-19</td>\n",
              "      <td>-5.083221e-15</td>\n",
              "      <td>4.233676e-15</td>\n",
              "      <td>-6.968064e-15</td>\n",
              "      <td>1.492889e-14</td>\n",
              "      <td>-7.717904e-16</td>\n",
              "      <td>-8.200821e-16</td>\n",
              "      <td>2.831166e-16</td>\n",
              "      <td>-7.238888e-17</td>\n",
              "      <td>-5.765196e-16</td>\n",
              "      <td>3.397741e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.118618e+04</td>\n",
              "      <td>1.878071e+00</td>\n",
              "      <td>2.074806e+00</td>\n",
              "      <td>4.931568e+00</td>\n",
              "      <td>1.876763e+01</td>\n",
              "      <td>1.186444e-01</td>\n",
              "      <td>2.299113e-01</td>\n",
              "      <td>2.824712e-01</td>\n",
              "      <td>1.970710e-01</td>\n",
              "      <td>1.656454e-01</td>\n",
              "      <td>8.406292e-02</td>\n",
              "      <td>5.268365e-01</td>\n",
              "      <td>7.430571e-01</td>\n",
              "      <td>1.422545e+00</td>\n",
              "      <td>6.747669e+00</td>\n",
              "      <td>5.481934e-02</td>\n",
              "      <td>1.338803e-01</td>\n",
              "      <td>1.738178e-01</td>\n",
              "      <td>7.858571e-02</td>\n",
              "      <td>9.095958e-02</td>\n",
              "      <td>5.146260e-02</td>\n",
              "      <td>2.199430e+00</td>\n",
              "      <td>2.480255e+00</td>\n",
              "      <td>5.799320e+00</td>\n",
              "      <td>2.387170e+01</td>\n",
              "      <td>1.511705e-01</td>\n",
              "      <td>3.968311e-01</td>\n",
              "      <td>4.569550e-01</td>\n",
              "      <td>2.564960e-01</td>\n",
              "      <td>2.488411e-01</td>\n",
              "      <td>1.344513e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.716735e+03</td>\n",
              "      <td>-3.808472e+00</td>\n",
              "      <td>-4.621192e+00</td>\n",
              "      <td>-9.778113e+00</td>\n",
              "      <td>-2.727245e+01</td>\n",
              "      <td>-3.689070e-01</td>\n",
              "      <td>-3.698632e-01</td>\n",
              "      <td>-3.146426e-01</td>\n",
              "      <td>-2.484495e-01</td>\n",
              "      <td>-4.541508e-01</td>\n",
              "      <td>-1.528487e-01</td>\n",
              "      <td>-5.579159e-01</td>\n",
              "      <td>-1.153891e+00</td>\n",
              "      <td>-1.483901e+00</td>\n",
              "      <td>-4.974249e+00</td>\n",
              "      <td>-9.727711e-02</td>\n",
              "      <td>-1.736370e-01</td>\n",
              "      <td>-1.836508e-01</td>\n",
              "      <td>-1.502374e-01</td>\n",
              "      <td>-1.393085e-01</td>\n",
              "      <td>-5.640321e-02</td>\n",
              "      <td>-3.794859e+00</td>\n",
              "      <td>-5.511223e+00</td>\n",
              "      <td>-9.811709e+00</td>\n",
              "      <td>-2.915566e+01</td>\n",
              "      <td>-4.051878e-01</td>\n",
              "      <td>-5.724722e-01</td>\n",
              "      <td>-5.961812e-01</td>\n",
              "      <td>-4.472081e-01</td>\n",
              "      <td>-5.372629e-01</td>\n",
              "      <td>-2.151801e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-2.639737e+03</td>\n",
              "      <td>-1.293576e+00</td>\n",
              "      <td>-1.504909e+00</td>\n",
              "      <td>-3.409426e+00</td>\n",
              "      <td>-1.251067e+01</td>\n",
              "      <td>-8.427762e-02</td>\n",
              "      <td>-1.716125e-01</td>\n",
              "      <td>-2.099026e-01</td>\n",
              "      <td>-1.452995e-01</td>\n",
              "      <td>-1.163860e-01</td>\n",
              "      <td>-6.069376e-02</td>\n",
              "      <td>-3.282310e-01</td>\n",
              "      <td>-5.158290e-01</td>\n",
              "      <td>-8.865577e-01</td>\n",
              "      <td>-3.335502e+00</td>\n",
              "      <td>-3.417820e-02</td>\n",
              "      <td>-9.268763e-02</td>\n",
              "      <td>-9.675939e-02</td>\n",
              "      <td>-5.295868e-02</td>\n",
              "      <td>-5.922449e-02</td>\n",
              "      <td>-3.008525e-02</td>\n",
              "      <td>-1.483137e+00</td>\n",
              "      <td>-1.855159e+00</td>\n",
              "      <td>-3.995569e+00</td>\n",
              "      <td>-1.531540e+01</td>\n",
              "      <td>-1.044018e-01</td>\n",
              "      <td>-2.700374e-01</td>\n",
              "      <td>-3.453890e-01</td>\n",
              "      <td>-1.938429e-01</td>\n",
              "      <td>-1.595817e-01</td>\n",
              "      <td>-9.294667e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.636444e+03</td>\n",
              "      <td>-4.035834e-01</td>\n",
              "      <td>-2.169090e-01</td>\n",
              "      <td>-1.162728e+00</td>\n",
              "      <td>-5.535086e+00</td>\n",
              "      <td>-4.135993e-03</td>\n",
              "      <td>-5.098178e-02</td>\n",
              "      <td>-9.658792e-02</td>\n",
              "      <td>-7.831041e-02</td>\n",
              "      <td>-1.185417e-02</td>\n",
              "      <td>-1.497350e-02</td>\n",
              "      <td>-1.538301e-01</td>\n",
              "      <td>-1.466229e-01</td>\n",
              "      <td>-4.074169e-01</td>\n",
              "      <td>-2.344660e+00</td>\n",
              "      <td>-1.206801e-02</td>\n",
              "      <td>-3.759002e-02</td>\n",
              "      <td>-3.457068e-02</td>\n",
              "      <td>-1.103126e-02</td>\n",
              "      <td>-1.994175e-02</td>\n",
              "      <td>-1.182293e-02</td>\n",
              "      <td>-5.912135e-01</td>\n",
              "      <td>-1.078350e-01</td>\n",
              "      <td>-1.657032e+00</td>\n",
              "      <td>-8.137414e+00</td>\n",
              "      <td>-7.075020e-03</td>\n",
              "      <td>-1.068523e-01</td>\n",
              "      <td>-9.963456e-02</td>\n",
              "      <td>-5.726849e-02</td>\n",
              "      <td>-3.167684e-02</td>\n",
              "      <td>-2.907561e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-1.928958e+03</td>\n",
              "      <td>8.807775e-01</td>\n",
              "      <td>1.210986e+00</td>\n",
              "      <td>2.462024e+00</td>\n",
              "      <td>6.816172e+00</td>\n",
              "      <td>7.541512e-02</td>\n",
              "      <td>1.134435e-01</td>\n",
              "      <td>1.484667e-01</td>\n",
              "      <td>1.273801e-01</td>\n",
              "      <td>8.784384e-02</td>\n",
              "      <td>3.955743e-02</td>\n",
              "      <td>1.400678e-01</td>\n",
              "      <td>3.463702e-01</td>\n",
              "      <td>3.454181e-01</td>\n",
              "      <td>7.198325e-01</td>\n",
              "      <td>2.017524e-02</td>\n",
              "      <td>5.212115e-02</td>\n",
              "      <td>5.848205e-02</td>\n",
              "      <td>3.711141e-02</td>\n",
              "      <td>3.232519e-02</td>\n",
              "      <td>1.484122e-02</td>\n",
              "      <td>1.147128e+00</td>\n",
              "      <td>1.631418e+00</td>\n",
              "      <td>3.130496e+00</td>\n",
              "      <td>8.528755e+00</td>\n",
              "      <td>9.025174e-02</td>\n",
              "      <td>2.139691e-01</td>\n",
              "      <td>2.424942e-01</td>\n",
              "      <td>1.825953e-01</td>\n",
              "      <td>1.119144e-01</td>\n",
              "      <td>6.055232e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.882261e+04</td>\n",
              "      <td>7.451802e+00</td>\n",
              "      <td>9.643282e+00</td>\n",
              "      <td>1.959132e+01</td>\n",
              "      <td>9.845333e+01</td>\n",
              "      <td>5.655445e-01</td>\n",
              "      <td>1.049409e+00</td>\n",
              "      <td>1.197638e+00</td>\n",
              "      <td>7.734006e-01</td>\n",
              "      <td>7.422253e-01</td>\n",
              "      <td>4.124633e-01</td>\n",
              "      <td>4.688360e+00</td>\n",
              "      <td>4.940905e+00</td>\n",
              "      <td>1.344827e+01</td>\n",
              "      <td>7.444119e+01</td>\n",
              "      <td>4.398123e-01</td>\n",
              "      <td>8.217682e-01</td>\n",
              "      <td>2.096602e+00</td>\n",
              "      <td>5.221042e-01</td>\n",
              "      <td>6.426931e-01</td>\n",
              "      <td>5.065429e-01</td>\n",
              "      <td>8.996968e+00</td>\n",
              "      <td>9.629563e+00</td>\n",
              "      <td>2.484178e+01</td>\n",
              "      <td>1.414388e+02</td>\n",
              "      <td>5.974102e-01</td>\n",
              "      <td>2.027165e+00</td>\n",
              "      <td>2.146106e+00</td>\n",
              "      <td>6.883110e-01</td>\n",
              "      <td>1.503181e+00</td>\n",
              "      <td>9.197596e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID      radius_1  ...    symmetry_3  fractal_dimension_3\n",
              "count  5.690000e+02  5.690000e+02  ...  5.690000e+02         5.690000e+02\n",
              "mean   7.272761e-14 -5.894914e-15  ... -5.765196e-16         3.397741e-16\n",
              "std    1.118618e+04  1.878071e+00  ...  2.488411e-01         1.344513e-01\n",
              "min   -2.716735e+03 -3.808472e+00  ... -5.372629e-01        -2.151801e-01\n",
              "25%   -2.639737e+03 -1.293576e+00  ... -1.595817e-01        -9.294667e-02\n",
              "50%   -2.636444e+03 -4.035834e-01  ... -3.167684e-02        -2.907561e-02\n",
              "75%   -1.928958e+03  8.807775e-01  ...  1.119144e-01         6.055232e-02\n",
              "max    7.882261e+04  7.451802e+00  ...  1.503181e+00         9.197596e-01\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "a6YEX3eQGGIp",
        "outputId": "50c53b3b-5fa0-49ae-f5c9-e4a9fddf7d81"
      },
      "source": [
        "ds.normalize('zscore', reset=True, save=True)\n",
        "ds.df_norm.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>radius_1</th>\n",
              "      <th>texture_1</th>\n",
              "      <th>perimeter_1</th>\n",
              "      <th>area_1</th>\n",
              "      <th>smoothness_1</th>\n",
              "      <th>compactness_1</th>\n",
              "      <th>concavity_1</th>\n",
              "      <th>concave_points_1</th>\n",
              "      <th>symmetry_1</th>\n",
              "      <th>fractal_dimension_1</th>\n",
              "      <th>radius_2</th>\n",
              "      <th>texture_2</th>\n",
              "      <th>perimeter_2</th>\n",
              "      <th>area_2</th>\n",
              "      <th>smoothness_2</th>\n",
              "      <th>compactness_2</th>\n",
              "      <th>concavity_2</th>\n",
              "      <th>concave_points_2</th>\n",
              "      <th>symmetry_2</th>\n",
              "      <th>fractal_dimension_2</th>\n",
              "      <th>radius_3</th>\n",
              "      <th>texture_3</th>\n",
              "      <th>perimeter_3</th>\n",
              "      <th>area_3</th>\n",
              "      <th>smoothness_3</th>\n",
              "      <th>compactness_3</th>\n",
              "      <th>concavity_3</th>\n",
              "      <th>concave_points_3</th>\n",
              "      <th>symmetry_3</th>\n",
              "      <th>fractal_dimension_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.877882e-18</td>\n",
              "      <td>-1.256562e-16</td>\n",
              "      <td>1.049736e-16</td>\n",
              "      <td>-1.272171e-16</td>\n",
              "      <td>-1.900452e-16</td>\n",
              "      <td>1.490704e-16</td>\n",
              "      <td>2.544342e-16</td>\n",
              "      <td>-1.338511e-16</td>\n",
              "      <td>-8.429110e-17</td>\n",
              "      <td>2.081912e-16</td>\n",
              "      <td>5.408679e-16</td>\n",
              "      <td>2.475807e-16</td>\n",
              "      <td>-9.912009e-17</td>\n",
              "      <td>-2.968237e-16</td>\n",
              "      <td>-1.088760e-16</td>\n",
              "      <td>4.426014e-16</td>\n",
              "      <td>1.958988e-16</td>\n",
              "      <td>1.678017e-16</td>\n",
              "      <td>2.185325e-17</td>\n",
              "      <td>1.523874e-16</td>\n",
              "      <td>-5.658430e-17</td>\n",
              "      <td>-7.988142e-16</td>\n",
              "      <td>-1.834112e-17</td>\n",
              "      <td>-4.015534e-16</td>\n",
              "      <td>-2.848727e-17</td>\n",
              "      <td>-2.189227e-16</td>\n",
              "      <td>-2.579464e-16</td>\n",
              "      <td>1.143393e-16</td>\n",
              "      <td>2.829215e-16</td>\n",
              "      <td>1.670212e-16</td>\n",
              "      <td>2.321908e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "      <td>1.000880e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.430790e-01</td>\n",
              "      <td>-2.029648e+00</td>\n",
              "      <td>-2.229249e+00</td>\n",
              "      <td>-1.984504e+00</td>\n",
              "      <td>-1.454443e+00</td>\n",
              "      <td>-3.112085e+00</td>\n",
              "      <td>-1.610136e+00</td>\n",
              "      <td>-1.114873e+00</td>\n",
              "      <td>-1.261820e+00</td>\n",
              "      <td>-2.744117e+00</td>\n",
              "      <td>-1.819865e+00</td>\n",
              "      <td>-1.059924e+00</td>\n",
              "      <td>-1.554264e+00</td>\n",
              "      <td>-1.044049e+00</td>\n",
              "      <td>-7.378291e-01</td>\n",
              "      <td>-1.776065e+00</td>\n",
              "      <td>-1.298098e+00</td>\n",
              "      <td>-1.057501e+00</td>\n",
              "      <td>-1.913447e+00</td>\n",
              "      <td>-1.532890e+00</td>\n",
              "      <td>-1.096968e+00</td>\n",
              "      <td>-1.726901e+00</td>\n",
              "      <td>-2.223994e+00</td>\n",
              "      <td>-1.693361e+00</td>\n",
              "      <td>-1.222423e+00</td>\n",
              "      <td>-2.682695e+00</td>\n",
              "      <td>-1.443878e+00</td>\n",
              "      <td>-1.305831e+00</td>\n",
              "      <td>-1.745063e+00</td>\n",
              "      <td>-2.160960e+00</td>\n",
              "      <td>-1.601839e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-2.361897e-01</td>\n",
              "      <td>-6.893853e-01</td>\n",
              "      <td>-7.259631e-01</td>\n",
              "      <td>-6.919555e-01</td>\n",
              "      <td>-6.671955e-01</td>\n",
              "      <td>-7.109628e-01</td>\n",
              "      <td>-7.470860e-01</td>\n",
              "      <td>-7.437479e-01</td>\n",
              "      <td>-7.379438e-01</td>\n",
              "      <td>-7.032397e-01</td>\n",
              "      <td>-7.226392e-01</td>\n",
              "      <td>-6.235706e-01</td>\n",
              "      <td>-6.948092e-01</td>\n",
              "      <td>-6.237679e-01</td>\n",
              "      <td>-4.947542e-01</td>\n",
              "      <td>-6.240183e-01</td>\n",
              "      <td>-6.929263e-01</td>\n",
              "      <td>-5.571612e-01</td>\n",
              "      <td>-6.744900e-01</td>\n",
              "      <td>-6.516807e-01</td>\n",
              "      <td>-5.851185e-01</td>\n",
              "      <td>-6.749213e-01</td>\n",
              "      <td>-7.486293e-01</td>\n",
              "      <td>-6.895783e-01</td>\n",
              "      <td>-6.421359e-01</td>\n",
              "      <td>-6.912304e-01</td>\n",
              "      <td>-6.810833e-01</td>\n",
              "      <td>-7.565142e-01</td>\n",
              "      <td>-7.563999e-01</td>\n",
              "      <td>-6.418637e-01</td>\n",
              "      <td>-6.919118e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.358950e-01</td>\n",
              "      <td>-2.150816e-01</td>\n",
              "      <td>-1.046362e-01</td>\n",
              "      <td>-2.359800e-01</td>\n",
              "      <td>-2.951869e-01</td>\n",
              "      <td>-3.489108e-02</td>\n",
              "      <td>-2.219405e-01</td>\n",
              "      <td>-3.422399e-01</td>\n",
              "      <td>-3.977212e-01</td>\n",
              "      <td>-7.162650e-02</td>\n",
              "      <td>-1.782793e-01</td>\n",
              "      <td>-2.922452e-01</td>\n",
              "      <td>-1.974976e-01</td>\n",
              "      <td>-2.866520e-01</td>\n",
              "      <td>-3.477828e-01</td>\n",
              "      <td>-2.203352e-01</td>\n",
              "      <td>-2.810204e-01</td>\n",
              "      <td>-1.990654e-01</td>\n",
              "      <td>-1.404958e-01</td>\n",
              "      <td>-2.194304e-01</td>\n",
              "      <td>-2.299405e-01</td>\n",
              "      <td>-2.690395e-01</td>\n",
              "      <td>-4.351564e-02</td>\n",
              "      <td>-2.859802e-01</td>\n",
              "      <td>-3.411812e-01</td>\n",
              "      <td>-4.684277e-02</td>\n",
              "      <td>-2.695009e-01</td>\n",
              "      <td>-2.182321e-01</td>\n",
              "      <td>-2.234689e-01</td>\n",
              "      <td>-1.274095e-01</td>\n",
              "      <td>-2.164441e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-1.725930e-01</td>\n",
              "      <td>4.693926e-01</td>\n",
              "      <td>5.841756e-01</td>\n",
              "      <td>4.996769e-01</td>\n",
              "      <td>3.635073e-01</td>\n",
              "      <td>6.361990e-01</td>\n",
              "      <td>4.938569e-01</td>\n",
              "      <td>5.260619e-01</td>\n",
              "      <td>6.469351e-01</td>\n",
              "      <td>5.307792e-01</td>\n",
              "      <td>4.709834e-01</td>\n",
              "      <td>2.660996e-01</td>\n",
              "      <td>4.665523e-01</td>\n",
              "      <td>2.430307e-01</td>\n",
              "      <td>1.067726e-01</td>\n",
              "      <td>3.683553e-01</td>\n",
              "      <td>3.896541e-01</td>\n",
              "      <td>3.367521e-01</td>\n",
              "      <td>4.726567e-01</td>\n",
              "      <td>3.556925e-01</td>\n",
              "      <td>2.886421e-01</td>\n",
              "      <td>5.220158e-01</td>\n",
              "      <td>6.583411e-01</td>\n",
              "      <td>5.402790e-01</td>\n",
              "      <td>3.575891e-01</td>\n",
              "      <td>5.975448e-01</td>\n",
              "      <td>5.396688e-01</td>\n",
              "      <td>5.311411e-01</td>\n",
              "      <td>7.125100e-01</td>\n",
              "      <td>4.501382e-01</td>\n",
              "      <td>4.507624e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.052629e+00</td>\n",
              "      <td>3.971288e+00</td>\n",
              "      <td>4.651889e+00</td>\n",
              "      <td>3.976130e+00</td>\n",
              "      <td>5.250529e+00</td>\n",
              "      <td>4.770911e+00</td>\n",
              "      <td>4.568425e+00</td>\n",
              "      <td>4.243589e+00</td>\n",
              "      <td>3.927930e+00</td>\n",
              "      <td>4.484751e+00</td>\n",
              "      <td>4.910919e+00</td>\n",
              "      <td>8.906909e+00</td>\n",
              "      <td>6.655279e+00</td>\n",
              "      <td>9.461986e+00</td>\n",
              "      <td>1.104184e+01</td>\n",
              "      <td>8.029999e+00</td>\n",
              "      <td>6.143482e+00</td>\n",
              "      <td>1.207268e+01</td>\n",
              "      <td>6.649601e+00</td>\n",
              "      <td>7.071917e+00</td>\n",
              "      <td>9.851593e+00</td>\n",
              "      <td>4.094189e+00</td>\n",
              "      <td>3.885905e+00</td>\n",
              "      <td>4.287337e+00</td>\n",
              "      <td>5.930172e+00</td>\n",
              "      <td>3.955374e+00</td>\n",
              "      <td>5.112877e+00</td>\n",
              "      <td>4.700669e+00</td>\n",
              "      <td>2.685877e+00</td>\n",
              "      <td>6.046041e+00</td>\n",
              "      <td>6.846856e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID      radius_1  ...    symmetry_3  fractal_dimension_3\n",
              "count  5.690000e+02  5.690000e+02  ...  5.690000e+02         5.690000e+02\n",
              "mean   8.877882e-18 -1.256562e-16  ...  1.670212e-16         2.321908e-16\n",
              "std    1.000880e+00  1.000880e+00  ...  1.000880e+00         1.000880e+00\n",
              "min   -2.430790e-01 -2.029648e+00  ... -2.160960e+00        -1.601839e+00\n",
              "25%   -2.361897e-01 -6.893853e-01  ... -6.418637e-01        -6.919118e-01\n",
              "50%   -2.358950e-01 -2.150816e-01  ... -1.274095e-01        -2.164441e-01\n",
              "75%   -1.725930e-01  4.693926e-01  ...  4.501382e-01         4.507624e-01\n",
              "max    7.052629e+00  3.971288e+00  ...  6.046041e+00         6.846856e+00\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "yPUelwh0NNl_",
        "outputId": "73bcdaac-05b5-4d4f-88ed-3b72f612cf98"
      },
      "source": [
        "ds.normalize('minmax', reset=True)\n",
        "ds.df_norm.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>radius_1</th>\n",
              "      <th>texture_1</th>\n",
              "      <th>perimeter_1</th>\n",
              "      <th>area_1</th>\n",
              "      <th>smoothness_1</th>\n",
              "      <th>compactness_1</th>\n",
              "      <th>concavity_1</th>\n",
              "      <th>concave_points_1</th>\n",
              "      <th>symmetry_1</th>\n",
              "      <th>fractal_dimension_1</th>\n",
              "      <th>radius_2</th>\n",
              "      <th>texture_2</th>\n",
              "      <th>perimeter_2</th>\n",
              "      <th>area_2</th>\n",
              "      <th>smoothness_2</th>\n",
              "      <th>compactness_2</th>\n",
              "      <th>concavity_2</th>\n",
              "      <th>concave_points_2</th>\n",
              "      <th>symmetry_2</th>\n",
              "      <th>fractal_dimension_2</th>\n",
              "      <th>radius_3</th>\n",
              "      <th>texture_3</th>\n",
              "      <th>perimeter_3</th>\n",
              "      <th>area_3</th>\n",
              "      <th>smoothness_3</th>\n",
              "      <th>compactness_3</th>\n",
              "      <th>concavity_3</th>\n",
              "      <th>concave_points_3</th>\n",
              "      <th>symmetry_3</th>\n",
              "      <th>fractal_dimension_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.033318</td>\n",
              "      <td>0.338222</td>\n",
              "      <td>0.323965</td>\n",
              "      <td>0.332935</td>\n",
              "      <td>0.216920</td>\n",
              "      <td>0.394785</td>\n",
              "      <td>0.260601</td>\n",
              "      <td>0.208058</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.379605</td>\n",
              "      <td>0.270379</td>\n",
              "      <td>0.106345</td>\n",
              "      <td>0.189324</td>\n",
              "      <td>0.099376</td>\n",
              "      <td>0.062636</td>\n",
              "      <td>0.181119</td>\n",
              "      <td>0.174439</td>\n",
              "      <td>0.080540</td>\n",
              "      <td>0.223454</td>\n",
              "      <td>0.178143</td>\n",
              "      <td>0.100193</td>\n",
              "      <td>0.296663</td>\n",
              "      <td>0.363998</td>\n",
              "      <td>0.283138</td>\n",
              "      <td>0.170906</td>\n",
              "      <td>0.404138</td>\n",
              "      <td>0.220212</td>\n",
              "      <td>0.217403</td>\n",
              "      <td>0.393836</td>\n",
              "      <td>0.263307</td>\n",
              "      <td>0.189596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.137187</td>\n",
              "      <td>0.166787</td>\n",
              "      <td>0.145453</td>\n",
              "      <td>0.167915</td>\n",
              "      <td>0.149274</td>\n",
              "      <td>0.126967</td>\n",
              "      <td>0.161992</td>\n",
              "      <td>0.186785</td>\n",
              "      <td>0.192857</td>\n",
              "      <td>0.138456</td>\n",
              "      <td>0.148702</td>\n",
              "      <td>0.100421</td>\n",
              "      <td>0.121917</td>\n",
              "      <td>0.095267</td>\n",
              "      <td>0.084967</td>\n",
              "      <td>0.102067</td>\n",
              "      <td>0.134498</td>\n",
              "      <td>0.076227</td>\n",
              "      <td>0.116884</td>\n",
              "      <td>0.116316</td>\n",
              "      <td>0.091417</td>\n",
              "      <td>0.171940</td>\n",
              "      <td>0.163813</td>\n",
              "      <td>0.167352</td>\n",
              "      <td>0.139932</td>\n",
              "      <td>0.150779</td>\n",
              "      <td>0.152649</td>\n",
              "      <td>0.166633</td>\n",
              "      <td>0.225884</td>\n",
              "      <td>0.121954</td>\n",
              "      <td>0.118466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000944</td>\n",
              "      <td>0.223342</td>\n",
              "      <td>0.218465</td>\n",
              "      <td>0.216847</td>\n",
              "      <td>0.117413</td>\n",
              "      <td>0.304595</td>\n",
              "      <td>0.139685</td>\n",
              "      <td>0.069260</td>\n",
              "      <td>0.100944</td>\n",
              "      <td>0.282323</td>\n",
              "      <td>0.163016</td>\n",
              "      <td>0.043781</td>\n",
              "      <td>0.104690</td>\n",
              "      <td>0.040004</td>\n",
              "      <td>0.020635</td>\n",
              "      <td>0.117483</td>\n",
              "      <td>0.081323</td>\n",
              "      <td>0.038106</td>\n",
              "      <td>0.144686</td>\n",
              "      <td>0.102409</td>\n",
              "      <td>0.046750</td>\n",
              "      <td>0.180719</td>\n",
              "      <td>0.241471</td>\n",
              "      <td>0.167837</td>\n",
              "      <td>0.081130</td>\n",
              "      <td>0.300007</td>\n",
              "      <td>0.116337</td>\n",
              "      <td>0.091454</td>\n",
              "      <td>0.223127</td>\n",
              "      <td>0.185098</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000985</td>\n",
              "      <td>0.302381</td>\n",
              "      <td>0.308759</td>\n",
              "      <td>0.293345</td>\n",
              "      <td>0.172895</td>\n",
              "      <td>0.390358</td>\n",
              "      <td>0.224679</td>\n",
              "      <td>0.144189</td>\n",
              "      <td>0.166501</td>\n",
              "      <td>0.369697</td>\n",
              "      <td>0.243892</td>\n",
              "      <td>0.077023</td>\n",
              "      <td>0.165267</td>\n",
              "      <td>0.072092</td>\n",
              "      <td>0.033112</td>\n",
              "      <td>0.158650</td>\n",
              "      <td>0.136675</td>\n",
              "      <td>0.065379</td>\n",
              "      <td>0.207047</td>\n",
              "      <td>0.152643</td>\n",
              "      <td>0.079191</td>\n",
              "      <td>0.250445</td>\n",
              "      <td>0.356876</td>\n",
              "      <td>0.235320</td>\n",
              "      <td>0.123206</td>\n",
              "      <td>0.397081</td>\n",
              "      <td>0.179110</td>\n",
              "      <td>0.181070</td>\n",
              "      <td>0.343402</td>\n",
              "      <td>0.247782</td>\n",
              "      <td>0.163977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.009661</td>\n",
              "      <td>0.416442</td>\n",
              "      <td>0.408860</td>\n",
              "      <td>0.416765</td>\n",
              "      <td>0.271135</td>\n",
              "      <td>0.475490</td>\n",
              "      <td>0.340531</td>\n",
              "      <td>0.306232</td>\n",
              "      <td>0.367793</td>\n",
              "      <td>0.453030</td>\n",
              "      <td>0.340354</td>\n",
              "      <td>0.133044</td>\n",
              "      <td>0.246155</td>\n",
              "      <td>0.122509</td>\n",
              "      <td>0.071700</td>\n",
              "      <td>0.218683</td>\n",
              "      <td>0.226800</td>\n",
              "      <td>0.106187</td>\n",
              "      <td>0.278651</td>\n",
              "      <td>0.219480</td>\n",
              "      <td>0.126556</td>\n",
              "      <td>0.386339</td>\n",
              "      <td>0.471748</td>\n",
              "      <td>0.373475</td>\n",
              "      <td>0.220901</td>\n",
              "      <td>0.494156</td>\n",
              "      <td>0.302520</td>\n",
              "      <td>0.305831</td>\n",
              "      <td>0.554639</td>\n",
              "      <td>0.318155</td>\n",
              "      <td>0.242949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               ID    radius_1  ...  symmetry_3  fractal_dimension_3\n",
              "count  569.000000  569.000000  ...  569.000000           569.000000\n",
              "mean     0.033318    0.338222  ...    0.263307             0.189596\n",
              "std      0.137187    0.166787  ...    0.121954             0.118466\n",
              "min      0.000000    0.000000  ...    0.000000             0.000000\n",
              "25%      0.000944    0.223342  ...    0.185098             0.107700\n",
              "50%      0.000985    0.302381  ...    0.247782             0.163977\n",
              "75%      0.009661    0.416442  ...    0.318155             0.242949\n",
              "max      1.000000    1.000000  ...    1.000000             1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "x40k8HGPNfWk",
        "outputId": "3177ff2c-a5aa-44b5-bf05-7992c01466df"
      },
      "source": [
        "ds.normalize('variablescaling', reset=True)\n",
        "ds.df_norm.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>radius_1</th>\n",
              "      <th>texture_1</th>\n",
              "      <th>perimeter_1</th>\n",
              "      <th>area_1</th>\n",
              "      <th>smoothness_1</th>\n",
              "      <th>compactness_1</th>\n",
              "      <th>concavity_1</th>\n",
              "      <th>concave_points_1</th>\n",
              "      <th>symmetry_1</th>\n",
              "      <th>fractal_dimension_1</th>\n",
              "      <th>radius_2</th>\n",
              "      <th>texture_2</th>\n",
              "      <th>perimeter_2</th>\n",
              "      <th>area_2</th>\n",
              "      <th>smoothness_2</th>\n",
              "      <th>compactness_2</th>\n",
              "      <th>concavity_2</th>\n",
              "      <th>concave_points_2</th>\n",
              "      <th>symmetry_2</th>\n",
              "      <th>fractal_dimension_2</th>\n",
              "      <th>radius_3</th>\n",
              "      <th>texture_3</th>\n",
              "      <th>perimeter_3</th>\n",
              "      <th>area_3</th>\n",
              "      <th>smoothness_3</th>\n",
              "      <th>compactness_3</th>\n",
              "      <th>concavity_3</th>\n",
              "      <th>concave_points_3</th>\n",
              "      <th>symmetry_3</th>\n",
              "      <th>fractal_dimension_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>5.690000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-2.134106e-18</td>\n",
              "      <td>-1.258903e-14</td>\n",
              "      <td>-2.969544e-14</td>\n",
              "      <td>-2.783167e-15</td>\n",
              "      <td>-1.602311e-15</td>\n",
              "      <td>4.139629e-14</td>\n",
              "      <td>-2.062790e-15</td>\n",
              "      <td>-3.855537e-16</td>\n",
              "      <td>1.394315e-15</td>\n",
              "      <td>-1.247508e-14</td>\n",
              "      <td>4.461184e-15</td>\n",
              "      <td>-1.394120e-15</td>\n",
              "      <td>-1.934793e-15</td>\n",
              "      <td>2.606195e-15</td>\n",
              "      <td>-6.933528e-16</td>\n",
              "      <td>-1.699188e-15</td>\n",
              "      <td>-4.686741e-16</td>\n",
              "      <td>1.112955e-15</td>\n",
              "      <td>-4.745277e-16</td>\n",
              "      <td>-7.683758e-16</td>\n",
              "      <td>2.185325e-17</td>\n",
              "      <td>-7.718879e-15</td>\n",
              "      <td>7.351276e-15</td>\n",
              "      <td>-3.724418e-15</td>\n",
              "      <td>9.166657e-16</td>\n",
              "      <td>-2.946754e-14</td>\n",
              "      <td>-3.494568e-15</td>\n",
              "      <td>8.729592e-16</td>\n",
              "      <td>-4.183336e-16</td>\n",
              "      <td>-1.160812e-14</td>\n",
              "      <td>1.163373e-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.433623e-01</td>\n",
              "      <td>4.015882e+00</td>\n",
              "      <td>4.492780e+00</td>\n",
              "      <td>3.791556e+00</td>\n",
              "      <td>1.864211e+00</td>\n",
              "      <td>6.863556e+00</td>\n",
              "      <td>1.979156e+00</td>\n",
              "      <td>1.115854e+00</td>\n",
              "      <td>1.262930e+00</td>\n",
              "      <td>6.619937e+00</td>\n",
              "      <td>8.910048e+00</td>\n",
              "      <td>1.463638e+00</td>\n",
              "      <td>2.209733e+00</td>\n",
              "      <td>1.420035e+00</td>\n",
              "      <td>8.882656e-01</td>\n",
              "      <td>2.349153e+00</td>\n",
              "      <td>1.425214e+00</td>\n",
              "      <td>1.058431e+00</td>\n",
              "      <td>1.915131e+00</td>\n",
              "      <td>2.489419e+00</td>\n",
              "      <td>1.436691e+00</td>\n",
              "      <td>3.372029e+00</td>\n",
              "      <td>4.185056e+00</td>\n",
              "      <td>3.197676e+00</td>\n",
              "      <td>1.549350e+00</td>\n",
              "      <td>5.807601e+00</td>\n",
              "      <td>1.618904e+00</td>\n",
              "      <td>1.306980e+00</td>\n",
              "      <td>1.746598e+00</td>\n",
              "      <td>4.696916e+00</td>\n",
              "      <td>4.656019e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-5.910427e-02</td>\n",
              "      <td>-8.143662e+00</td>\n",
              "      <td>-1.000672e+01</td>\n",
              "      <td>-7.517744e+00</td>\n",
              "      <td>-2.709005e+00</td>\n",
              "      <td>-2.134119e+01</td>\n",
              "      <td>-3.183909e+00</td>\n",
              "      <td>-1.242941e+00</td>\n",
              "      <td>-1.592189e+00</td>\n",
              "      <td>-1.814991e+01</td>\n",
              "      <td>-1.620083e+01</td>\n",
              "      <td>-1.549981e+00</td>\n",
              "      <td>-3.431489e+00</td>\n",
              "      <td>-1.481283e+00</td>\n",
              "      <td>-6.548120e-01</td>\n",
              "      <td>-4.168581e+00</td>\n",
              "      <td>-1.848442e+00</td>\n",
              "      <td>-1.118308e+00</td>\n",
              "      <td>-3.661281e+00</td>\n",
              "      <td>-3.812651e+00</td>\n",
              "      <td>-1.574618e+00</td>\n",
              "      <td>-5.818040e+00</td>\n",
              "      <td>-9.299356e+00</td>\n",
              "      <td>-5.410060e+00</td>\n",
              "      <td>-1.892296e+00</td>\n",
              "      <td>-1.556632e+01</td>\n",
              "      <td>-2.335446e+00</td>\n",
              "      <td>-1.705194e+00</td>\n",
              "      <td>-3.045244e+00</td>\n",
              "      <td>-1.014092e+01</td>\n",
              "      <td>-7.451639e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-5.742914e-02</td>\n",
              "      <td>-2.766056e+00</td>\n",
              "      <td>-3.258726e+00</td>\n",
              "      <td>-2.621282e+00</td>\n",
              "      <td>-1.242699e+00</td>\n",
              "      <td>-4.875443e+00</td>\n",
              "      <td>-1.477300e+00</td>\n",
              "      <td>-8.291843e-01</td>\n",
              "      <td>-9.311519e-01</td>\n",
              "      <td>-4.651310e+00</td>\n",
              "      <td>-6.433090e+00</td>\n",
              "      <td>-9.118792e-01</td>\n",
              "      <td>-1.533993e+00</td>\n",
              "      <td>-8.849938e-01</td>\n",
              "      <td>-4.390868e-01</td>\n",
              "      <td>-1.464626e+00</td>\n",
              "      <td>-9.867003e-01</td>\n",
              "      <td>-5.891984e-01</td>\n",
              "      <td>-1.290601e+00</td>\n",
              "      <td>-1.620880e+00</td>\n",
              "      <td>-8.398951e-01</td>\n",
              "      <td>-2.273854e+00</td>\n",
              "      <td>-3.130301e+00</td>\n",
              "      <td>-2.203110e+00</td>\n",
              "      <td>-9.940188e-01</td>\n",
              "      <td>-4.010861e+00</td>\n",
              "      <td>-1.101639e+00</td>\n",
              "      <td>-9.878794e-01</td>\n",
              "      <td>-1.319965e+00</td>\n",
              "      <td>-3.012129e+00</td>\n",
              "      <td>-3.218722e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-5.735750e-02</td>\n",
              "      <td>-8.629830e-01</td>\n",
              "      <td>-4.696943e-01</td>\n",
              "      <td>-8.939450e-01</td>\n",
              "      <td>-5.498067e-01</td>\n",
              "      <td>-2.392663e-01</td>\n",
              "      <td>-4.388687e-01</td>\n",
              "      <td>-3.815540e-01</td>\n",
              "      <td>-5.018524e-01</td>\n",
              "      <td>-4.737461e-01</td>\n",
              "      <td>-1.587080e+00</td>\n",
              "      <td>-4.273650e-01</td>\n",
              "      <td>-4.360332e-01</td>\n",
              "      <td>-4.066982e-01</td>\n",
              "      <td>-3.086519e-01</td>\n",
              "      <td>-5.171462e-01</td>\n",
              "      <td>-4.001622e-01</td>\n",
              "      <td>-2.105118e-01</td>\n",
              "      <td>-2.688313e-01</td>\n",
              "      <td>-5.457741e-01</td>\n",
              "      <td>-3.300628e-01</td>\n",
              "      <td>-9.064116e-01</td>\n",
              "      <td>-1.819553e-01</td>\n",
              "      <td>-9.136681e-01</td>\n",
              "      <td>-5.281445e-01</td>\n",
              "      <td>-2.718050e-01</td>\n",
              "      <td>-4.359125e-01</td>\n",
              "      <td>-2.849741e-01</td>\n",
              "      <td>-3.899673e-01</td>\n",
              "      <td>-5.979054e-01</td>\n",
              "      <td>-1.006882e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-4.196570e-02</td>\n",
              "      <td>1.883368e+00</td>\n",
              "      <td>2.622266e+00</td>\n",
              "      <td>1.892888e+00</td>\n",
              "      <td>6.770585e-01</td>\n",
              "      <td>4.362749e+00</td>\n",
              "      <td>9.765605e-01</td>\n",
              "      <td>5.864921e-01</td>\n",
              "      <td>8.163154e-01</td>\n",
              "      <td>3.510635e+00</td>\n",
              "      <td>4.192795e+00</td>\n",
              "      <td>3.891311e-01</td>\n",
              "      <td>1.030050e+00</td>\n",
              "      <td>3.448088e-01</td>\n",
              "      <td>9.475901e-02</td>\n",
              "      <td>8.645623e-01</td>\n",
              "      <td>5.548524e-01</td>\n",
              "      <td>3.561156e-01</td>\n",
              "      <td>9.044038e-01</td>\n",
              "      <td>8.846893e-01</td>\n",
              "      <td>4.143249e-01</td>\n",
              "      <td>1.758705e+00</td>\n",
              "      <td>2.752772e+00</td>\n",
              "      <td>1.726119e+00</td>\n",
              "      <td>5.535437e-01</td>\n",
              "      <td>3.467251e+00</td>\n",
              "      <td>8.729041e-01</td>\n",
              "      <td>6.935803e-01</td>\n",
              "      <td>1.243375e+00</td>\n",
              "      <td>2.112402e+00</td>\n",
              "      <td>2.096913e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.714835e+00</td>\n",
              "      <td>1.593420e+01</td>\n",
              "      <td>2.088154e+01</td>\n",
              "      <td>1.506247e+01</td>\n",
              "      <td>9.779487e+00</td>\n",
              "      <td>3.271663e+01</td>\n",
              "      <td>9.033677e+00</td>\n",
              "      <td>4.731062e+00</td>\n",
              "      <td>4.956339e+00</td>\n",
              "      <td>2.966267e+01</td>\n",
              "      <td>4.371806e+01</td>\n",
              "      <td>1.302503e+01</td>\n",
              "      <td>1.469346e+01</td>\n",
              "      <td>1.342454e+01</td>\n",
              "      <td>9.799466e+00</td>\n",
              "      <td>1.884712e+01</td>\n",
              "      <td>8.748082e+00</td>\n",
              "      <td>1.276687e+01</td>\n",
              "      <td>1.272366e+01</td>\n",
              "      <td>1.758949e+01</td>\n",
              "      <td>1.414125e+01</td>\n",
              "      <td>1.379359e+01</td>\n",
              "      <td>1.624843e+01</td>\n",
              "      <td>1.369747e+01</td>\n",
              "      <td>9.179837e+00</td>\n",
              "      <td>2.295104e+01</td>\n",
              "      <td>8.269981e+00</td>\n",
              "      <td>6.138277e+00</td>\n",
              "      <td>4.687024e+00</td>\n",
              "      <td>2.837278e+01</td>\n",
              "      <td>3.185107e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID      radius_1  ...    symmetry_3  fractal_dimension_3\n",
              "count  5.690000e+02  5.690000e+02  ...  5.690000e+02         5.690000e+02\n",
              "mean  -2.134106e-18 -1.258903e-14  ... -1.160812e-14         1.163373e-14\n",
              "std    2.433623e-01  4.015882e+00  ...  4.696916e+00         4.656019e+00\n",
              "min   -5.910427e-02 -8.143662e+00  ... -1.014092e+01        -7.451639e+00\n",
              "25%   -5.742914e-02 -2.766056e+00  ... -3.012129e+00        -3.218722e+00\n",
              "50%   -5.735750e-02 -8.629830e-01  ... -5.979054e-01        -1.006882e+00\n",
              "75%   -4.196570e-02  1.883368e+00  ...  2.112402e+00         2.096913e+00\n",
              "max    1.714835e+00  1.593420e+01  ...  2.837278e+01         3.185107e+01\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bojRvYj5Nluf"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "\n",
        "from sys import platform\n",
        "from normal_methods import load_data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "\n",
        "SEPARATOR = '\\\\' if platform == 'win32' else '/'\n",
        "\n",
        "class ModelClass():\n",
        "    def __init__(self,data:dict) -> None:\n",
        "        self.datasets = data\n",
        "\n",
        "    def run_models(self):\n",
        "        \"\"\"#!ISAK From this method you can return whatever you want to get to your output \"\"\"\n",
        "        \n",
        "        for dataset_name in self.datasets.keys():\n",
        "            print(f\"############# DATASET NAME AND METHOD: {dataset_name} ############\")\n",
        "            df = self.datasets[dataset_name][\"data\"].copy() #copy dataframe \n",
        "            \n",
        "            categorical = df.select_dtypes('category')\n",
        "            \n",
        "            df[categorical.columns] = categorical.apply(LabelEncoder().fit_transform)\n",
        "            target = self.datasets[dataset_name][\"target\"]\n",
        "            \n",
        "\n",
        "            if self.datasets[dataset_name][\"pred_type\"] ==\"regression\":\n",
        "                ### TODO: adapt model\n",
        "                print(\"regression\")\n",
        "            elif self.datasets[dataset_name][\"pred_type\"]==\"classification\": \n",
        "                ### TODO: adapt model\n",
        "                print(\"classification\")\n",
        "            else: #both, run all\n",
        "                raise TypeError(\"Prediction type not supported\")\n",
        "      \n",
        "            X = df.drop([target], axis=1)\n",
        "            y = df[target]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            y_pred = self.train_model(X_train,X_test,y_train,y_test)    \n",
        "            \n",
        "    def evaluate(self,y_test,y_pred, type=\"regression\"):\n",
        "        if type == \"regression\":\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            print(\"The model performance for testing set\")\n",
        "            print(\"--------------------------------------\")\n",
        "            print('MAE is {}'.format(mae))\n",
        "            print('MSE is {}'.format(mse))\n",
        "            print('R2 score is {}'.format(r2))\n",
        "        else:\n",
        "            print(\"Classification report\")\n",
        "            print(classification_report(y_test, y_pred))\n",
        "            print(\"Confusion matrix\")\n",
        "            print(confusion_matrix(y_test, y_pred))\n",
        "            print(\"Accuracy score\")\n",
        "            print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "               \n",
        "    def train_model(self,X_train,X_test,y_train,y_test, pred_type=\"classification\"):\n",
        "        \"\"\"\n",
        "        Here we train the models and get access to data for evaluation\n",
        "        \n",
        "        \"\"\"\n",
        "        print(\"**********NN************\")\n",
        "        model = Sequential()\n",
        "        model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        \n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        model.fit(X_train, y_train, epochs=100, batch_size=10)\n",
        "        \n",
        "        _, accuracy = model.evaluate(X_train, y_train)\n",
        "        print('Accuracy: %.2f' % (accuracy*100))\n",
        "        \n",
        "        y_pred =  model.predict(X_test)\n",
        "        # print(y_test)\n",
        "        # print(y_pred)\n",
        "        if (pred_type == \"classification\"):\n",
        "            y_pred = np.where( np.array(y_pred) > 0.5, 1, 0)\n",
        "        self.evaluate(y_test,y_pred,type=pred_type)\n",
        "        print(\"************************\")\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "def read_data(dataset_name):\n",
        "    path = os.path.join(os.getcwd(),rf\"output{SEPARATOR}post_norma_data\")\n",
        "    files = glob.glob(os.path.join(path,f\"{dataset_name}*.csv\"))\n",
        "    if len(files)==0:\n",
        "        return None #no data here\n",
        "    \n",
        "    #files.append(os.path.join(path,f\"{dataset_name}_.csv\"))\n",
        "\n",
        "    config = json.load(open(\"dataset_config.json\"))[\"datasets\"]\n",
        "    datasets = {}\n",
        "    for f in files:\n",
        "        \n",
        "        norm_method = os.path.basename(f)\n",
        "        print(f\"Training model for {norm_method.split('_')[1].upper()}\")\n",
        "        \n",
        "        dtype = config[dataset_name][\"dtype\"]\n",
        "        df = pd.read_csv(f,dtype=dtype)\n",
        "        datasets[norm_method] = {\"data\":df,\"target\":config[dataset_name][\"target\"],\"pred_type\":config[dataset_name][\"pred_type\"],\"pred_type\":config[dataset_name][\"pred_type\"]}\n",
        "\n",
        "    #adding unnormalized data for comparison\n",
        "    datasets[f\"{dataset_name}_UnNorm\"] = {\"data\":load_data(dataset_name),\"target\":config[dataset_name][\"target\"],\"pred_type\":config[dataset_name][\"pred_type\"]}\n",
        "    return datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX6hunHPqg6D"
      },
      "source": [
        "def run_advanced_models(dataset)->str:\n",
        "    data = read_data(dataset)\n",
        "    if data is None:\n",
        "        return \"No data available for dataset\"\n",
        "    else:\n",
        "        print(\"Running basic models for dataset {}\".format(dataset))\n",
        "        models = ModelClass(data)\n",
        "        models.run_models()\n",
        "        return \"Models trained\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cXg1FWujrx1D",
        "outputId": "78f1403d-5a67-4494-de2a-e8a92306425b"
      },
      "source": [
        "run_advanced_models(\"breastCancer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for ZSCORE.CSV\n",
            "Running basic models for dataset breastCancer\n",
            "############# DATASET NAME AND METHOD: breastCancer_zscore.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7077\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.9121\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9429\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9560\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9626\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9780\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9780\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9824\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9846\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9846\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9846\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9846\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9868\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9868\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9890\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9890\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9890\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9890\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9912\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9934\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9934\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9934\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9934\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9934\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9934\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9934\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9934\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9934\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9934\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9956\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9934\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9934\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9934\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9934\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9956\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9934\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9934\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9934\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9956\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9956\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9978\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9934\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9978\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 9.9845e-04 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 9.4560e-04 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 8.3950e-04 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 8.4680e-04 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.6470e-04 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.1315e-04 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.0774e-04 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.7551e-04 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.5254e-04 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.1225e-04 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.9672e-04 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.8131e-04 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.4721e-04 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.0971e-04 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.0803e-04 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.7961e-04 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.7587e-04 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.5469e-04 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.1110e-04 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.2275e-04 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.0109e-04 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.9677e-04 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.7249e-04 - accuracy: 1.0000\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9930\n",
            "Accuracy: 99.30\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        71\n",
            "           1       0.95      0.95      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Confusion matrix\n",
            "[[69  2]\n",
            " [ 2 41]]\n",
            "Accuracy score\n",
            "0.9649122807017544\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: breastCancer_UnNorm ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 333781.9375 - accuracy: 0.5473\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 138613.4844 - accuracy: 0.5363\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 48953.3047 - accuracy: 0.5429\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 223040.8281 - accuracy: 0.4835\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 174271.5469 - accuracy: 0.4747\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 187048.5781 - accuracy: 0.5231\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 158942.6250 - accuracy: 0.4835\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 56354.3750 - accuracy: 0.4703\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 106831.1562 - accuracy: 0.5516\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 102655.0859 - accuracy: 0.5407\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 208944.8750 - accuracy: 0.5714\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 175659.1094 - accuracy: 0.5165\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 84517.5625 - accuracy: 0.5209\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 237491.8125 - accuracy: 0.5187\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 150883.5312 - accuracy: 0.5890\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 81002.6484 - accuracy: 0.4879\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 92108.6484 - accuracy: 0.5275\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 84857.1172 - accuracy: 0.5297\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 107126.2188 - accuracy: 0.5121\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 61570.7500 - accuracy: 0.5055\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 228316.8750 - accuracy: 0.5187\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 81203.7188 - accuracy: 0.4769\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 43951.1953 - accuracy: 0.4989\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 84190.5703 - accuracy: 0.5077\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 165279.4531 - accuracy: 0.5099\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 365639.5000 - accuracy: 0.5473\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 228798.3281 - accuracy: 0.5604\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 89198.5078 - accuracy: 0.4000\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 350598.5000 - accuracy: 0.5363\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 178178.2812 - accuracy: 0.5802\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 319006.8438 - accuracy: 0.5209\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 129771.7812 - accuracy: 0.5297\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 91754.6406 - accuracy: 0.5495\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 93336.4453 - accuracy: 0.4945\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 171143.6719 - accuracy: 0.5670\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 215900.8906 - accuracy: 0.4879\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 133294.2500 - accuracy: 0.4703\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 66029.6953 - accuracy: 0.4747\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 132951.8906 - accuracy: 0.5121\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 155417.9375 - accuracy: 0.4396\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 59031.4961 - accuracy: 0.5275\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 47467.0273 - accuracy: 0.5626\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 64158.4648 - accuracy: 0.4484\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 82228.9141 - accuracy: 0.4286\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 116785.6875 - accuracy: 0.4374\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 123872.5156 - accuracy: 0.5209\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 158111.3594 - accuracy: 0.4989\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 177848.7812 - accuracy: 0.4813\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 54930.8516 - accuracy: 0.4901\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 235101.1094 - accuracy: 0.5451\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 49485.5508 - accuracy: 0.5297\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 58847.6758 - accuracy: 0.4681\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 92995.9141 - accuracy: 0.5407\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 68533.6016 - accuracy: 0.5011\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 75835.7266 - accuracy: 0.5187\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 43799.4258 - accuracy: 0.5319\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 39592.1250 - accuracy: 0.5011\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 56082.4336 - accuracy: 0.4527\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 61710.9727 - accuracy: 0.5099\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 57391.8945 - accuracy: 0.4242\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 156723.2344 - accuracy: 0.5011\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 39933.7305 - accuracy: 0.6000\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 14410.7910 - accuracy: 0.4681\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 98044.7578 - accuracy: 0.5209\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 67455.6562 - accuracy: 0.5121\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 130859.2188 - accuracy: 0.4813\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 16251.3281 - accuracy: 0.5802\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 31646.0625 - accuracy: 0.4857\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 67854.5234 - accuracy: 0.5143\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 31514.8926 - accuracy: 0.5121\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 26395.7578 - accuracy: 0.5033\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 65776.7266 - accuracy: 0.5692\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 29088.9941 - accuracy: 0.5055\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 55171.6992 - accuracy: 0.4374\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 181264.1875 - accuracy: 0.5099\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 36628.3359 - accuracy: 0.4791\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 75249.1094 - accuracy: 0.5121\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 68083.4453 - accuracy: 0.4681\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 92651.4609 - accuracy: 0.5582\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 41341.9297 - accuracy: 0.5670\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 114940.5547 - accuracy: 0.4637\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 63413.9688 - accuracy: 0.5099\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 98349.3516 - accuracy: 0.5099\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 25689.0312 - accuracy: 0.5934\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 170437.5625 - accuracy: 0.4593\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 33730.6641 - accuracy: 0.5143\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 27416.3516 - accuracy: 0.4945\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 94913.1484 - accuracy: 0.5495\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 162538.5312 - accuracy: 0.4747\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 89506.9531 - accuracy: 0.5670\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 93435.0000 - accuracy: 0.4484\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 58937.7969 - accuracy: 0.6022\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 167115.0938 - accuracy: 0.5143\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 96166.1875 - accuracy: 0.5033\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 120495.1562 - accuracy: 0.5077\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 40465.6094 - accuracy: 0.4813\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 22896.5781 - accuracy: 0.6088\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 60982.6641 - accuracy: 0.5099\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 71822.2422 - accuracy: 0.5626\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 100130.2422 - accuracy: 0.5714\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.4065 - accuracy: 0.5923\n",
            "Accuracy: 59.23\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77        71\n",
            "           1       1.00      0.02      0.05        43\n",
            "\n",
            "    accuracy                           0.63       114\n",
            "   macro avg       0.81      0.51      0.41       114\n",
            "weighted avg       0.77      0.63      0.50       114\n",
            "\n",
            "Confusion matrix\n",
            "[[71  0]\n",
            " [42  1]]\n",
            "Accuracy score\n",
            "0.631578947368421\n",
            "************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Models trained'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlt0X-yMsG8j",
        "outputId": "f9b22a60-d9a0-4667-cce0-f12e376d5b3d"
      },
      "source": [
        "datasets = read_data(\"breastCancer\")\n",
        "df = datasets[\"breastCancer_zscore.csv\"][\"data\"].copy() #copy dataframe \n",
        "            \n",
        "categorical = df.select_dtypes('category')\n",
        "\n",
        "df[categorical.columns] = categorical.apply(LabelEncoder().fit_transform)\n",
        "target = datasets[\"breastCancer_zscore.csv\"][\"target\"]\n",
        "\n",
        "\n",
        "if datasets[\"breastCancer_zscore.csv\"][\"pred_type\"] ==\"regression\":\n",
        "    ### TODO: adapt model\n",
        "    print(\"regression\")\n",
        "elif datasets[\"breastCancer_zscore.csv\"][\"pred_type\"]==\"classification\": \n",
        "    ### TODO: adapt model\n",
        "    print(\"classification\")\n",
        "else: #both, run all\n",
        "    raise TypeError(\"Prediction type not supported\")\n",
        "\n",
        "X = df.drop([target], axis=1)\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for ZSCORE.CSV\n",
            "classification\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC8k_7AluZ26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um48N-U4UVks"
      },
      "source": [
        "from normal_methods import z_score, Normalizator\n",
        "import numpy as np\n",
        "\n",
        "ds_wine = Normalizator(dataset=\"wine\")\n",
        "ds_wine.df.describe()\n",
        "ds_wine.normalize('tanh', reset=True,save=True)\n",
        "ds_wine.normalize('zscore', reset=True, save=True)\n",
        "ds_wine.normalize('pareto', reset=True, save=True)\n",
        "ds_wine.normalize('minmax', reset=True, save=True)\n",
        "ds_wine.normalize('variablescaling', reset=True, save=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsZq7kB0U20M"
      },
      "source": [
        "ds_adult = Normalizator(dataset=\"adult\")\n",
        "ds_adult.df.describe()\n",
        "ds_adult.normalize('tanh', reset=True,save=True)\n",
        "ds_adult.normalize('zscore', reset=True, save=True)\n",
        "ds_adult.normalize('pareto', reset=True, save=True)\n",
        "ds_adult.normalize('minmax', reset=True, save=True)\n",
        "ds_adult.normalize('variablescaling', reset=True, save=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsDsBaI9U8GA"
      },
      "source": [
        "ds_bc = Normalizator(dataset=\"breastCancer\")\n",
        "ds_bc.df.describe()\n",
        "ds_bc.normalize('tanh', reset=True,save=True)\n",
        "ds_bc.normalize('zscore', reset=True, save=True)\n",
        "ds_bc.normalize('pareto', reset=True, save=True)\n",
        "ds_bc.normalize('minmax', reset=True, save=True)\n",
        "ds_bc.normalize('variablescaling', reset=True, save=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bsS4PfT5WLPr",
        "outputId": "8606d37a-c922-4e27-efb1-1696b1b821e3"
      },
      "source": [
        "from adv_models import run_advanced_models\n",
        "\n",
        "run_advanced_models(\"adult\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for MINMAX.CSV\n",
            "Training model for TANH.CSV\n",
            "Training model for VARIABLESCALING.CSV\n",
            "Training model for PARETO.CSV\n",
            "Training model for ZSCORE.CSV\n",
            "Running advanced models for dataset adult\n",
            "############# DATASET NAME AND METHOD: adult_minmax.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.4758 - accuracy: 0.7660\n",
            "Epoch 2/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4038 - accuracy: 0.8050\n",
            "Epoch 3/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3778 - accuracy: 0.8176\n",
            "Epoch 4/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3671 - accuracy: 0.8262\n",
            "Epoch 5/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3594 - accuracy: 0.8284\n",
            "Epoch 6/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3562 - accuracy: 0.8299\n",
            "Epoch 7/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3497 - accuracy: 0.8366\n",
            "Epoch 8/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3505 - accuracy: 0.8336\n",
            "Epoch 9/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3481 - accuracy: 0.8342\n",
            "Epoch 10/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3470 - accuracy: 0.8346\n",
            "Epoch 11/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3476 - accuracy: 0.8366\n",
            "Epoch 12/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3414 - accuracy: 0.8382\n",
            "Epoch 13/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3433 - accuracy: 0.8374\n",
            "Epoch 14/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3402 - accuracy: 0.8395\n",
            "Epoch 15/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3397 - accuracy: 0.8385\n",
            "Epoch 16/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.8401\n",
            "Epoch 17/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3387 - accuracy: 0.8390\n",
            "Epoch 18/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3366 - accuracy: 0.8405\n",
            "Epoch 19/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3378 - accuracy: 0.8393\n",
            "Epoch 20/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3360 - accuracy: 0.8403\n",
            "Epoch 21/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3363 - accuracy: 0.8395\n",
            "Epoch 22/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3348 - accuracy: 0.8404\n",
            "Epoch 23/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3340 - accuracy: 0.8423\n",
            "Epoch 24/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3335 - accuracy: 0.8422\n",
            "Epoch 25/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3320 - accuracy: 0.8427\n",
            "Epoch 26/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3317 - accuracy: 0.8437\n",
            "Epoch 27/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3305 - accuracy: 0.8440\n",
            "Epoch 28/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3304 - accuracy: 0.8433\n",
            "Epoch 29/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3306 - accuracy: 0.8439\n",
            "Epoch 30/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3299 - accuracy: 0.8426\n",
            "Epoch 31/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3295 - accuracy: 0.8432\n",
            "Epoch 32/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3286 - accuracy: 0.8453\n",
            "Epoch 33/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3278 - accuracy: 0.8452\n",
            "Epoch 34/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3270 - accuracy: 0.8443\n",
            "Epoch 35/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3274 - accuracy: 0.8436\n",
            "Epoch 36/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3276 - accuracy: 0.8453\n",
            "Epoch 37/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3266 - accuracy: 0.8456\n",
            "Epoch 38/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3262 - accuracy: 0.8454\n",
            "Epoch 39/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3268 - accuracy: 0.8456\n",
            "Epoch 40/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3264 - accuracy: 0.8459\n",
            "Epoch 41/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3239 - accuracy: 0.8477\n",
            "Epoch 42/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3243 - accuracy: 0.8461\n",
            "Epoch 43/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3242 - accuracy: 0.8469\n",
            "Epoch 44/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3235 - accuracy: 0.8461\n",
            "Epoch 45/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3240 - accuracy: 0.8480\n",
            "Epoch 46/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3239 - accuracy: 0.8464\n",
            "Epoch 47/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3233 - accuracy: 0.8479\n",
            "Epoch 48/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3230 - accuracy: 0.8470\n",
            "Epoch 49/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3241 - accuracy: 0.8459\n",
            "Epoch 50/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3229 - accuracy: 0.8486\n",
            "814/814 [==============================] - 1s 1ms/step - loss: 0.3187 - accuracy: 0.8483\n",
            "Accuracy: 84.83\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90      4942\n",
            "           1       0.71      0.63      0.67      1571\n",
            "\n",
            "    accuracy                           0.85      6513\n",
            "   macro avg       0.80      0.77      0.78      6513\n",
            "weighted avg       0.84      0.85      0.85      6513\n",
            "\n",
            "Confusion matrix\n",
            "[[4540  402]\n",
            " [ 585  986]]\n",
            "Accuracy score\n",
            "0.8484569322892677\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: adult_tanh.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5924 - accuracy: 0.7475\n",
            "Epoch 2/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4455 - accuracy: 0.7617\n",
            "Epoch 3/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4351 - accuracy: 0.7659\n",
            "Epoch 4/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4311 - accuracy: 0.7642\n",
            "Epoch 5/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4281 - accuracy: 0.7649\n",
            "Epoch 6/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4263 - accuracy: 0.7677\n",
            "Epoch 7/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4221 - accuracy: 0.7725\n",
            "Epoch 8/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4227 - accuracy: 0.7735\n",
            "Epoch 9/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4196 - accuracy: 0.7779\n",
            "Epoch 10/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4170 - accuracy: 0.7855\n",
            "Epoch 11/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4158 - accuracy: 0.7826\n",
            "Epoch 12/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4150 - accuracy: 0.7839\n",
            "Epoch 13/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4135 - accuracy: 0.7851\n",
            "Epoch 14/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4131 - accuracy: 0.7875\n",
            "Epoch 15/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4115 - accuracy: 0.7883\n",
            "Epoch 16/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4108 - accuracy: 0.7898\n",
            "Epoch 17/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.4097 - accuracy: 0.7938\n",
            "Epoch 18/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4087 - accuracy: 0.7945\n",
            "Epoch 19/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4089 - accuracy: 0.7944\n",
            "Epoch 20/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4075 - accuracy: 0.7964\n",
            "Epoch 21/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4063 - accuracy: 0.7973\n",
            "Epoch 22/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4059 - accuracy: 0.7989\n",
            "Epoch 23/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4048 - accuracy: 0.7979\n",
            "Epoch 24/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4034 - accuracy: 0.7995\n",
            "Epoch 25/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4021 - accuracy: 0.8020\n",
            "Epoch 26/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4011 - accuracy: 0.8027\n",
            "Epoch 27/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3989 - accuracy: 0.8044\n",
            "Epoch 28/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3982 - accuracy: 0.8047\n",
            "Epoch 29/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3974 - accuracy: 0.8082\n",
            "Epoch 30/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3953 - accuracy: 0.8101\n",
            "Epoch 31/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3945 - accuracy: 0.8083\n",
            "Epoch 32/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3934 - accuracy: 0.8111\n",
            "Epoch 33/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3927 - accuracy: 0.8108\n",
            "Epoch 34/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3914 - accuracy: 0.8135\n",
            "Epoch 35/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3907 - accuracy: 0.8128\n",
            "Epoch 36/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3895 - accuracy: 0.8117\n",
            "Epoch 37/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3881 - accuracy: 0.8130\n",
            "Epoch 38/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3880 - accuracy: 0.8155\n",
            "Epoch 39/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3889 - accuracy: 0.8143\n",
            "Epoch 40/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3881 - accuracy: 0.8151\n",
            "Epoch 41/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3879 - accuracy: 0.8155\n",
            "Epoch 42/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3863 - accuracy: 0.8166\n",
            "Epoch 43/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3854 - accuracy: 0.8156\n",
            "Epoch 44/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3851 - accuracy: 0.8158\n",
            "Epoch 45/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3850 - accuracy: 0.8161\n",
            "Epoch 46/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3840 - accuracy: 0.8165\n",
            "Epoch 47/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3833 - accuracy: 0.8179\n",
            "Epoch 48/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3828 - accuracy: 0.8187\n",
            "Epoch 49/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3832 - accuracy: 0.8174\n",
            "Epoch 50/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3820 - accuracy: 0.8206\n",
            "814/814 [==============================] - 1s 1ms/step - loss: 0.3795 - accuracy: 0.8239\n",
            "Accuracy: 82.39\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.89      4942\n",
            "           1       0.68      0.44      0.54      1571\n",
            "\n",
            "    accuracy                           0.82      6513\n",
            "   macro avg       0.76      0.69      0.71      6513\n",
            "weighted avg       0.80      0.82      0.80      6513\n",
            "\n",
            "Confusion matrix\n",
            "[[4616  326]\n",
            " [ 873  698]]\n",
            "Accuracy score\n",
            "0.8159066482419776\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: adult_variablescaling.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.4268 - accuracy: 0.7984\n",
            "Epoch 2/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3782 - accuracy: 0.8208\n",
            "Epoch 3/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3545 - accuracy: 0.8328\n",
            "Epoch 4/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3468 - accuracy: 0.8366\n",
            "Epoch 5/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3424 - accuracy: 0.8372\n",
            "Epoch 6/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3389 - accuracy: 0.8417\n",
            "Epoch 7/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3354 - accuracy: 0.8425\n",
            "Epoch 8/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3320 - accuracy: 0.8436\n",
            "Epoch 9/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3311 - accuracy: 0.8435\n",
            "Epoch 10/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3295 - accuracy: 0.8433\n",
            "Epoch 11/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3283 - accuracy: 0.8454\n",
            "Epoch 12/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3276 - accuracy: 0.8446\n",
            "Epoch 13/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3258 - accuracy: 0.8439\n",
            "Epoch 14/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3253 - accuracy: 0.8461\n",
            "Epoch 15/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3245 - accuracy: 0.8474\n",
            "Epoch 16/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3237 - accuracy: 0.8472\n",
            "Epoch 17/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3215 - accuracy: 0.8470\n",
            "Epoch 18/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3227 - accuracy: 0.8476\n",
            "Epoch 19/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3206 - accuracy: 0.8471\n",
            "Epoch 20/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3204 - accuracy: 0.8489\n",
            "Epoch 21/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3199 - accuracy: 0.8483\n",
            "Epoch 22/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3211 - accuracy: 0.8477\n",
            "Epoch 23/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3189 - accuracy: 0.8485\n",
            "Epoch 24/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3188 - accuracy: 0.8499\n",
            "Epoch 25/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3178 - accuracy: 0.8492\n",
            "Epoch 26/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3173 - accuracy: 0.8500\n",
            "Epoch 27/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3164 - accuracy: 0.8496\n",
            "Epoch 28/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3165 - accuracy: 0.8509\n",
            "Epoch 29/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3163 - accuracy: 0.8503\n",
            "Epoch 30/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3145 - accuracy: 0.8524\n",
            "Epoch 31/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3147 - accuracy: 0.8507\n",
            "Epoch 32/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3141 - accuracy: 0.8501\n",
            "Epoch 33/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3148 - accuracy: 0.8493\n",
            "Epoch 34/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3137 - accuracy: 0.8511\n",
            "Epoch 35/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3142 - accuracy: 0.8495\n",
            "Epoch 36/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3139 - accuracy: 0.8528\n",
            "Epoch 37/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3133 - accuracy: 0.8513\n",
            "Epoch 38/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3128 - accuracy: 0.8521\n",
            "Epoch 39/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3122 - accuracy: 0.8531\n",
            "Epoch 40/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3120 - accuracy: 0.8528\n",
            "Epoch 41/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3110 - accuracy: 0.8528\n",
            "Epoch 42/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3113 - accuracy: 0.8520\n",
            "Epoch 43/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3106 - accuracy: 0.8530\n",
            "Epoch 44/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3109 - accuracy: 0.8537\n",
            "Epoch 45/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3102 - accuracy: 0.8530\n",
            "Epoch 46/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3096 - accuracy: 0.8535\n",
            "Epoch 47/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3098 - accuracy: 0.8526\n",
            "Epoch 48/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3088 - accuracy: 0.8546\n",
            "Epoch 49/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3107 - accuracy: 0.8525\n",
            "Epoch 50/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3085 - accuracy: 0.8535\n",
            "814/814 [==============================] - 1s 1ms/step - loss: 0.3062 - accuracy: 0.8547\n",
            "Accuracy: 85.47\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      4942\n",
            "           1       0.77      0.53      0.62      1571\n",
            "\n",
            "    accuracy                           0.85      6513\n",
            "   macro avg       0.81      0.74      0.76      6513\n",
            "weighted avg       0.84      0.85      0.84      6513\n",
            "\n",
            "Confusion matrix\n",
            "[[4690  252]\n",
            " [ 744  827]]\n",
            "Accuracy score\n",
            "0.8470750806080147\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: adult_pareto.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5923 - accuracy: 0.7895\n",
            "Epoch 2/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4328 - accuracy: 0.8077\n",
            "Epoch 3/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4153 - accuracy: 0.8123\n",
            "Epoch 4/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.4043 - accuracy: 0.8175\n",
            "Epoch 5/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3975 - accuracy: 0.8209\n",
            "Epoch 6/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3929 - accuracy: 0.8228\n",
            "Epoch 7/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3834 - accuracy: 0.8260\n",
            "Epoch 8/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3786 - accuracy: 0.8283\n",
            "Epoch 9/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3751 - accuracy: 0.8300\n",
            "Epoch 10/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3695 - accuracy: 0.8311\n",
            "Epoch 11/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3668 - accuracy: 0.8322\n",
            "Epoch 12/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3618 - accuracy: 0.8348\n",
            "Epoch 13/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3570 - accuracy: 0.8364\n",
            "Epoch 14/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3548 - accuracy: 0.8364\n",
            "Epoch 15/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3462 - accuracy: 0.8381\n",
            "Epoch 16/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3398 - accuracy: 0.8406\n",
            "Epoch 17/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3357 - accuracy: 0.8415\n",
            "Epoch 18/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3327 - accuracy: 0.8435\n",
            "Epoch 19/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3314 - accuracy: 0.8433\n",
            "Epoch 20/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3298 - accuracy: 0.8457\n",
            "Epoch 21/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3290 - accuracy: 0.8463\n",
            "Epoch 22/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3284 - accuracy: 0.8466\n",
            "Epoch 23/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3270 - accuracy: 0.8467\n",
            "Epoch 24/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3247 - accuracy: 0.8462\n",
            "Epoch 25/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3250 - accuracy: 0.8476\n",
            "Epoch 26/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3245 - accuracy: 0.8465\n",
            "Epoch 27/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3237 - accuracy: 0.8467\n",
            "Epoch 28/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3220 - accuracy: 0.8488\n",
            "Epoch 29/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3210 - accuracy: 0.8490\n",
            "Epoch 30/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3209 - accuracy: 0.8501\n",
            "Epoch 31/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3218 - accuracy: 0.8475\n",
            "Epoch 32/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3201 - accuracy: 0.8482\n",
            "Epoch 33/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3198 - accuracy: 0.8496\n",
            "Epoch 34/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3187 - accuracy: 0.8482\n",
            "Epoch 35/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3200 - accuracy: 0.8497\n",
            "Epoch 36/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3196 - accuracy: 0.8484\n",
            "Epoch 37/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3180 - accuracy: 0.8494\n",
            "Epoch 38/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3176 - accuracy: 0.8497\n",
            "Epoch 39/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3193 - accuracy: 0.8499\n",
            "Epoch 40/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3173 - accuracy: 0.8504\n",
            "Epoch 41/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3186 - accuracy: 0.8491\n",
            "Epoch 42/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3163 - accuracy: 0.8508\n",
            "Epoch 43/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3168 - accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3174 - accuracy: 0.8506\n",
            "Epoch 45/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3170 - accuracy: 0.8515\n",
            "Epoch 46/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3153 - accuracy: 0.8521\n",
            "Epoch 47/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3160 - accuracy: 0.8506\n",
            "Epoch 48/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3164 - accuracy: 0.8513\n",
            "Epoch 49/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3142 - accuracy: 0.8515\n",
            "Epoch 50/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3151 - accuracy: 0.8519\n",
            "814/814 [==============================] - 1s 1ms/step - loss: 0.3130 - accuracy: 0.8506\n",
            "Accuracy: 85.06\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91      4942\n",
            "           1       0.77      0.54      0.64      1571\n",
            "\n",
            "    accuracy                           0.85      6513\n",
            "   macro avg       0.82      0.75      0.77      6513\n",
            "weighted avg       0.84      0.85      0.84      6513\n",
            "\n",
            "Confusion matrix\n",
            "[[4691  251]\n",
            " [ 719  852]]\n",
            "Accuracy score\n",
            "0.8510670965760786\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: adult_zscore.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.4056 - accuracy: 0.8145\n",
            "Epoch 2/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3605 - accuracy: 0.8324\n",
            "Epoch 3/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3454 - accuracy: 0.8379\n",
            "Epoch 4/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3401 - accuracy: 0.8409\n",
            "Epoch 5/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3370 - accuracy: 0.8402\n",
            "Epoch 6/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3332 - accuracy: 0.8426\n",
            "Epoch 7/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3316 - accuracy: 0.8423\n",
            "Epoch 8/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3294 - accuracy: 0.8449\n",
            "Epoch 9/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3278 - accuracy: 0.8456\n",
            "Epoch 10/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3262 - accuracy: 0.8453\n",
            "Epoch 11/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3261 - accuracy: 0.8450\n",
            "Epoch 12/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3246 - accuracy: 0.8467\n",
            "Epoch 13/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3233 - accuracy: 0.8446\n",
            "Epoch 14/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3231 - accuracy: 0.8469\n",
            "Epoch 15/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3222 - accuracy: 0.8472\n",
            "Epoch 16/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3211 - accuracy: 0.8487\n",
            "Epoch 17/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3203 - accuracy: 0.8489\n",
            "Epoch 18/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3195 - accuracy: 0.8514\n",
            "Epoch 19/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3189 - accuracy: 0.8482\n",
            "Epoch 20/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3189 - accuracy: 0.8489\n",
            "Epoch 21/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3177 - accuracy: 0.8495\n",
            "Epoch 22/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3172 - accuracy: 0.8497\n",
            "Epoch 23/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3167 - accuracy: 0.8501\n",
            "Epoch 24/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3160 - accuracy: 0.8538\n",
            "Epoch 25/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3152 - accuracy: 0.8505\n",
            "Epoch 26/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3146 - accuracy: 0.8527\n",
            "Epoch 27/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3143 - accuracy: 0.8522\n",
            "Epoch 28/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3149 - accuracy: 0.8510\n",
            "Epoch 29/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3137 - accuracy: 0.8512\n",
            "Epoch 30/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3131 - accuracy: 0.8509\n",
            "Epoch 31/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3128 - accuracy: 0.8523\n",
            "Epoch 32/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3124 - accuracy: 0.8508\n",
            "Epoch 33/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3123 - accuracy: 0.8519\n",
            "Epoch 34/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3111 - accuracy: 0.8528\n",
            "Epoch 35/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3113 - accuracy: 0.8527\n",
            "Epoch 36/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3103 - accuracy: 0.8532\n",
            "Epoch 37/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3105 - accuracy: 0.8528\n",
            "Epoch 38/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3093 - accuracy: 0.8532\n",
            "Epoch 39/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3091 - accuracy: 0.8532\n",
            "Epoch 40/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3089 - accuracy: 0.8549\n",
            "Epoch 41/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3078 - accuracy: 0.8538\n",
            "Epoch 42/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3086 - accuracy: 0.8527\n",
            "Epoch 43/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3075 - accuracy: 0.8537\n",
            "Epoch 44/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3073 - accuracy: 0.8535\n",
            "Epoch 45/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3071 - accuracy: 0.8547\n",
            "Epoch 46/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.3056 - accuracy: 0.8555\n",
            "Epoch 47/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3061 - accuracy: 0.8558\n",
            "Epoch 48/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3060 - accuracy: 0.8560\n",
            "Epoch 49/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3047 - accuracy: 0.8564\n",
            "Epoch 50/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.3041 - accuracy: 0.8552\n",
            "814/814 [==============================] - 1s 1ms/step - loss: 0.3050 - accuracy: 0.8566\n",
            "Accuracy: 85.66\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91      4942\n",
            "           1       0.75      0.60      0.67      1571\n",
            "\n",
            "    accuracy                           0.86      6513\n",
            "   macro avg       0.81      0.77      0.79      6513\n",
            "weighted avg       0.85      0.86      0.85      6513\n",
            "\n",
            "Confusion matrix\n",
            "[[4625  317]\n",
            " [ 626  945]]\n",
            "Accuracy score\n",
            "0.8552126516198373\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: adult_UnNorm ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 153.5782 - accuracy: 0.6850\n",
            "Epoch 2/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 62.4280 - accuracy: 0.6843\n",
            "Epoch 3/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 51.1608 - accuracy: 0.6861\n",
            "Epoch 4/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 43.4376 - accuracy: 0.6851\n",
            "Epoch 5/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 34.8785 - accuracy: 0.6890\n",
            "Epoch 6/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 33.5656 - accuracy: 0.6930\n",
            "Epoch 7/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 24.6643 - accuracy: 0.6912\n",
            "Epoch 8/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 18.5950 - accuracy: 0.6970\n",
            "Epoch 9/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 11.9049 - accuracy: 0.6938\n",
            "Epoch 10/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 9.0512 - accuracy: 0.6956\n",
            "Epoch 11/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 7.1175 - accuracy: 0.7042\n",
            "Epoch 12/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 5.0738 - accuracy: 0.7013\n",
            "Epoch 13/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 2.8330 - accuracy: 0.7111\n",
            "Epoch 14/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 1.2038 - accuracy: 0.7354\n",
            "Epoch 15/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5113 - accuracy: 0.7909\n",
            "Epoch 16/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.4985 - accuracy: 0.7948\n",
            "Epoch 17/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5167 - accuracy: 0.7869\n",
            "Epoch 18/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5499 - accuracy: 0.7637\n",
            "Epoch 19/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5512 - accuracy: 0.7598\n",
            "Epoch 20/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5512 - accuracy: 0.7598\n",
            "Epoch 21/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5512 - accuracy: 0.7598\n",
            "Epoch 22/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5512 - accuracy: 0.7598\n",
            "Epoch 23/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5512 - accuracy: 0.7598\n",
            "Epoch 24/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5512 - accuracy: 0.7598\n",
            "Epoch 25/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5498 - accuracy: 0.7608\n",
            "Epoch 26/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5453 - accuracy: 0.7640\n",
            "Epoch 27/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 28/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 29/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 30/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 31/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 32/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 33/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 34/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 35/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 36/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 37/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 38/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 39/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 40/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 41/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 42/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 43/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 44/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 45/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 46/50\n",
            "2605/2605 [==============================] - 5s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 47/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Epoch 48/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 49/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "Epoch 50/50\n",
            "2605/2605 [==============================] - 4s 2ms/step - loss: 0.5508 - accuracy: 0.7601\n",
            "814/814 [==============================] - 1s 1ms/step - loss: 0.5507 - accuracy: 0.7601\n",
            "Accuracy: 76.01\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86      4942\n",
            "           1       1.00      0.01      0.01      1571\n",
            "\n",
            "    accuracy                           0.76      6513\n",
            "   macro avg       0.88      0.50      0.44      6513\n",
            "weighted avg       0.82      0.76      0.66      6513\n",
            "\n",
            "Confusion matrix\n",
            "[[4942    0]\n",
            " [1562    9]]\n",
            "Accuracy score\n",
            "0.7601719637647781\n",
            "************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Models trained'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J95CGaSDWXIp",
        "outputId": "9b38aa96-baba-47d3-ae64-b90ca9a61a5a"
      },
      "source": [
        "\n",
        "run_advanced_models(\"wine\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for ZSCORE.CSV\n",
            "Training model for MINMAX.CSV\n",
            "Training model for PARETO.CSV\n",
            "Training model for TANH.CSV\n",
            "Training model for VARIABLESCALING.CSV\n",
            "Running advanced models for dataset wine\n",
            "############# DATASET NAME AND METHOD: wine_zscore.csv ############\n",
            "regression\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -780.7842 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -14441.8291 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -63019.0391 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -160180.5938 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -314023.7812 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -530740.6875 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -814862.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1169414.5000 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1597687.7500 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2104119.2500 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2692909.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3367307.7500 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4131737.2500 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4988034.5000 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -5943166.5000 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -7001021.0000 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -8166578.5000 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -9441943.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -10829057.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -12337520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -13969810.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -15725323.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -17609018.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -19629100.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -21790466.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -24091916.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -26539420.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -29140348.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -31894986.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -34809084.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -37886132.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -41134204.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -44554100.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -48142600.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -51912212.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -55862436.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -59998428.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -64318876.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -68828600.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -73548568.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -78480456.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -83612872.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -88953432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -94507024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -100278320.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -106272480.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -112488504.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -118936112.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -125606080.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -132511256.0000 - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 0s 1ms/step - loss: -136055264.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "The model performance for testing set\n",
            "--------------------------------------\n",
            "MAE is 4.817692307692307\n",
            "MSE is 23.925384615384615\n",
            "R2 score is -32.45152891751763\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: wine_minmax.csv ############\n",
            "regression\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -906.6988 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -13965.1572 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -56556.4023 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -140118.5000 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -272523.0938 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -457915.6250 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -699951.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1001944.5000 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1366590.2500 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1797211.8750 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2297281.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2869723.5000 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3518161.2500 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4245257.5000 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -5054674.5000 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -5949941.5000 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -6935057.0000 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -8012941.5000 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -9186617.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -10459221.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -11834546.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -13315187.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -14906015.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -16611191.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -18431446.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -20370972.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -22433798.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -24621390.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -26938080.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -29388132.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -31975648.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -34704092.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -37573472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -40587676.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -43751064.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -47065432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -50537800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -54168240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -57959688.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -61918460.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -66044164.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -70342480.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -74816352.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -79468928.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -84302072.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -89319112.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -94523896.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -99920888.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -105512944.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -111302616.0000 - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 0s 1ms/step - loss: -114270432.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "The model performance for testing set\n",
            "--------------------------------------\n",
            "MAE is 4.817692307692307\n",
            "MSE is 23.925384615384615\n",
            "R2 score is -32.45152891751763\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: wine_pareto.csv ############\n",
            "regression\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2193.0667 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -31325.9258 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -125808.3984 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -309290.1562 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -596882.8125 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -996530.5000 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1514821.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2158512.2500 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2936857.5000 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3855865.5000 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4922886.5000 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -6145813.0000 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -7531268.0000 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -9081922.0000 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -10805939.0000 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -12716252.0000 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -14816322.0000 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -17113050.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -19613496.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -22325786.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -25251884.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -28407978.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -31797702.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -35427200.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -39297604.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -43419920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -47810560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -52476472.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -57412568.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -62630612.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -68128944.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -73916784.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -80014240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -86437400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -93172496.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -100238992.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -107643104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -115372616.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -123452512.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -131877968.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -140655712.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "520/520 [==============================] - 1s 1ms/step - loss: -149773728.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -159286320.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -169168160.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -179423136.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -190077520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -201137840.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -212622320.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -224522848.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -236824336.0000 - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 0s 1ms/step - loss: -243127520.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "The model performance for testing set\n",
            "--------------------------------------\n",
            "MAE is 4.817692307692307\n",
            "MSE is 23.925384615384615\n",
            "R2 score is -32.45152891751763\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: wine_tanh.csv ############\n",
            "regression\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -744.5778 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -11454.7002 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -46991.5859 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -116549.3828 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -225656.5938 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -378023.9688 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -576758.6875 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -824358.9375 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1123248.7500 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1476072.8750 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1885608.3750 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2354520.7500 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2884894.2500 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3479916.5000 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4142230.2500 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4875069.5000 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -5680669.5000 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -6561506.5000 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -7521272.5000 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -8562157.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -9687206.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -10898706.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -12199528.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -13592278.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -15080044.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -16665662.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -18351530.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -20141212.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -22036000.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -24038972.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -26153288.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -28381146.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -30726646.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -33191730.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -35777392.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -38488488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -41326508.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -44293592.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -47392580.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -50627268.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -53998664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -57510400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -61166596.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -64969296.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -68919016.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -73018488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -77271560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -81680224.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -86248704.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -90978968.0000 - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 0s 1ms/step - loss: -93406704.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "The model performance for testing set\n",
            "--------------------------------------\n",
            "MAE is 4.817692307692307\n",
            "MSE is 23.925384615384615\n",
            "R2 score is -32.45152891751763\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: wine_variablescaling.csv ############\n",
            "regression\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -41098.2031 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -656820.5625 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2668209.7500 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -6556873.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -12606602.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -21068952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -32122596.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -45853992.0000 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -62504728.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -82181248.0000 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -104951512.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -130999024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -160571456.0000 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -193643024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -230326192.0000 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -271063040.0000 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -316001344.0000 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -365152160.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -418445312.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -476154432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -538528064.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -605761920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -678029952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -755618816.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -838486848.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -926647808.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1020559744.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1120318208.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1225566080.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1337062272.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1455000448.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1578635008.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1708811008.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1845445760.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1988788480.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2139228032.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2296974080.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2462303744.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2634984448.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2815072768.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3002339072.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3198097408.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3401632256.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3612442880.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3831440896.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4058367744.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4294295040.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4538706432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4792093696.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -5054884864.0000 - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 0s 1ms/step - loss: -5189975040.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "The model performance for testing set\n",
            "--------------------------------------\n",
            "MAE is 4.817692307692307\n",
            "MSE is 23.925384615384615\n",
            "R2 score is -32.45152891751763\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: wine_UnNorm ############\n",
            "regression\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -47744.4883 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -694433.8125 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2756526.5000 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -6747488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -12983284.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -21677584.0000 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -32999448.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -47078004.0000 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -64081452.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -84154632.0000 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -107411400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -134035104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -164195632.0000 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -198011120.0000 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -235613856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -277135808.0000 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -322774784.0000 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -372741440.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -427187776.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -486241696.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -550043520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -618733248.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -692509952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -771468800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -855761728.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -945635904.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1041309504.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1142787328.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1250183040.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1363798144.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1483648512.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1609925376.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1742731520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -1882394496.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2028907648.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2182273024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2343137024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2511279616.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2686831360.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -2870199296.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3061339648.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3260395520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3467356928.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3682720768.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -3906409984.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4138519040.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4379250176.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4628991488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -4887933440.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "520/520 [==============================] - 1s 2ms/step - loss: -5156148736.0000 - accuracy: 0.0000e+00\n",
            "163/163 [==============================] - 0s 1ms/step - loss: -5293507584.0000 - accuracy: 0.0000e+00\n",
            "Accuracy: 0.00\n",
            "The model performance for testing set\n",
            "--------------------------------------\n",
            "MAE is 4.817692307692307\n",
            "MSE is 23.925384615384615\n",
            "R2 score is -32.45152891751763\n",
            "************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Models trained'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJ8bXhg3Xtl-",
        "outputId": "771baf58-6193-4034-94fe-548c4375d973"
      },
      "source": [
        "\n",
        "run_advanced_models(\"breastCancer\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for MINMAX.CSV\n",
            "Training model for ZSCORE.CSV\n",
            "Training model for VARIABLESCALING.CSV\n",
            "Training model for TANH.CSV\n",
            "Training model for PARETO.CSV\n",
            "Running advanced models for dataset breastCancer\n",
            "############# DATASET NAME AND METHOD: breastCancer_minmax.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6687 - accuracy: 0.7363\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.8615\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8967\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.9077\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8989\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2237 - accuracy: 0.9121\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9253\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9231\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9495\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9385\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9560\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9429\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9582\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9670\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9670\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9714\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9736\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9846\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9780\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9736\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9780\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9780\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9780\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9824\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9780\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9758\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9802\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9780\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9780\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9846\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9824\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9802\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9846\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9802\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9802\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9802\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9780\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9846\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9890\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9824\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9780\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9890\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9780\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9846\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9868\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9824\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9868\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9846\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9868\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9846\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9890\n",
            "Accuracy: 98.90\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98        71\n",
            "           1       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "Confusion matrix\n",
            "[[70  1]\n",
            " [ 2 41]]\n",
            "Accuracy score\n",
            "0.9736842105263158\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: breastCancer_zscore.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7560\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9077\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9363\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9648\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9758\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9824\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9846\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9846\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9868\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9846\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9868\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9890\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9890\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9912\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9934\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9912\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9934\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9934\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9956\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9934\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9956\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9934\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9956\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9956\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9956\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9934\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9956\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9978\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9934\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9956\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9978\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9956\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9978\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9978\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9978\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9978\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Accuracy: 100.00\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98        71\n",
            "           1       0.98      0.95      0.96        43\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "Confusion matrix\n",
            "[[70  1]\n",
            " [ 2 41]]\n",
            "Accuracy score\n",
            "0.9736842105263158\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: breastCancer_variablescaling.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6535 - accuracy: 0.6945\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9385\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9560\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9670\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9714\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9780\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9780\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9824\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9868\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9824\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9868\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9868\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9868\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9868\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9890\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9846\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9868\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9890\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9868\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9956\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9956\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9956\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9956\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9956\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9956\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9934\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9956\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9978\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9978\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9978\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9978\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9978\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9978\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9978\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Accuracy: 100.00\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97        71\n",
            "           1       0.95      0.93      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Confusion matrix\n",
            "[[69  2]\n",
            " [ 3 40]]\n",
            "Accuracy score\n",
            "0.956140350877193\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: breastCancer_tanh.csv ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.6666 - accuracy: 0.6286\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6286\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.6286\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6286\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6286\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6286\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6286\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6286\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6286\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6286\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6286\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6286\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6286\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6286\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6286\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6286\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6286\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6286\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6286\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6286\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6286\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6286\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6286\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6286\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6286\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6286\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6286\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6286\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6286\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6286\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6286\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6286\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6286\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6286\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6286\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6286\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6286\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6286\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6286\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6286\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6286\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6286\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6286\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.6286\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6286\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6286\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6286\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6286\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6286\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.6286\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6286\n",
            "Accuracy: 62.86\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.77        71\n",
            "           1       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.62       114\n",
            "   macro avg       0.31      0.50      0.38       114\n",
            "weighted avg       0.39      0.62      0.48       114\n",
            "\n",
            "Confusion matrix\n",
            "[[71  0]\n",
            " [43  0]]\n",
            "Accuracy score\n",
            "0.6228070175438597\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: breastCancer_pareto.csv ############\n",
            "classification\n",
            "**********NN************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 117.9990 - accuracy: 0.5429\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 20.0574 - accuracy: 0.8000\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 10.1540 - accuracy: 0.7890\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.2311 - accuracy: 0.8747\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.5962 - accuracy: 0.8418\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.5523 - accuracy: 0.8527\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.4211 - accuracy: 0.8813\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 15.8492 - accuracy: 0.8352\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.0746 - accuracy: 0.8066\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.0284 - accuracy: 0.8044\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1.7172 - accuracy: 0.8308\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.6004 - accuracy: 0.8440\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 10.5586 - accuracy: 0.8286\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.3553 - accuracy: 0.8813\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.4877 - accuracy: 0.8835\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.8401 - accuracy: 0.8813\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.2646 - accuracy: 0.8505\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.0398 - accuracy: 0.8659\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.6735 - accuracy: 0.8396\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.7748 - accuracy: 0.8462\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 9.6683 - accuracy: 0.8923\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.9531 - accuracy: 0.8703\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.0843 - accuracy: 0.8923\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.2249 - accuracy: 0.8989\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.6006 - accuracy: 0.9099\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 3.5315 - accuracy: 0.9099\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 7.4217 - accuracy: 0.8967\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.3530 - accuracy: 0.8725\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.5978 - accuracy: 0.9099\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1.7758 - accuracy: 0.8813\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.4235 - accuracy: 0.8747\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.1903 - accuracy: 0.9253\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 9.0834 - accuracy: 0.8769\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.1957 - accuracy: 0.9165\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.4380 - accuracy: 0.8813\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 10.2706 - accuracy: 0.8418\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.9374 - accuracy: 0.9077\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.2534 - accuracy: 0.9033\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.8189 - accuracy: 0.9253\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 4.8044 - accuracy: 0.9033\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 6.5385 - accuracy: 0.8835\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.1898 - accuracy: 0.9055\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.2002 - accuracy: 0.9077\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2.4679 - accuracy: 0.9407\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 14.6518 - accuracy: 0.8593\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 5.9393 - accuracy: 0.8967\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.5308 - accuracy: 0.9121\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1.1802 - accuracy: 0.9319\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4.6580 - accuracy: 0.9121\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1.6625 - accuracy: 0.9231\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 10.9899 - accuracy: 0.8659\n",
            "Accuracy: 86.59\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.91        71\n",
            "           1       0.81      0.91      0.86        43\n",
            "\n",
            "    accuracy                           0.89       114\n",
            "   macro avg       0.88      0.89      0.88       114\n",
            "weighted avg       0.89      0.89      0.89       114\n",
            "\n",
            "Confusion matrix\n",
            "[[62  9]\n",
            " [ 4 39]]\n",
            "Accuracy score\n",
            "0.8859649122807017\n",
            "************************\n",
            "############# DATASET NAME AND METHOD: breastCancer_UnNorm ############\n",
            "classification\n",
            "**********NN************\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 348780.8438 - accuracy: 0.5736\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 218265.9219 - accuracy: 0.4527\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 91931.9766 - accuracy: 0.5341\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 60993.9375 - accuracy: 0.4923\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 322641.3438 - accuracy: 0.5099\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 134374.4844 - accuracy: 0.4923\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 49334.2930 - accuracy: 0.4549\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 78388.9141 - accuracy: 0.4637\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 94385.7969 - accuracy: 0.4989\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 164279.6094 - accuracy: 0.4835\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 166549.8906 - accuracy: 0.5429\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 43412.4570 - accuracy: 0.5143\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 96575.0703 - accuracy: 0.5033\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 39860.6562 - accuracy: 0.4593\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 55840.8555 - accuracy: 0.5407\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 74940.2109 - accuracy: 0.4418\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 81270.6797 - accuracy: 0.4879\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 46328.8281 - accuracy: 0.4901\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 56059.4453 - accuracy: 0.4396\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 162936.6719 - accuracy: 0.4703\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 65837.9453 - accuracy: 0.5385\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 43204.3359 - accuracy: 0.5626\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 114309.0781 - accuracy: 0.4308\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 66154.7656 - accuracy: 0.5253\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 26478.5547 - accuracy: 0.5121\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 41131.0977 - accuracy: 0.4857\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 89398.8203 - accuracy: 0.5341\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 29625.2949 - accuracy: 0.5209\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 96675.5391 - accuracy: 0.4901\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 111756.0781 - accuracy: 0.4791\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 34282.0273 - accuracy: 0.5758\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 47225.3594 - accuracy: 0.5429\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 53708.6016 - accuracy: 0.5341\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 13714.2451 - accuracy: 0.4967\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 62050.1055 - accuracy: 0.5055\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 123346.4375 - accuracy: 0.5187\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 117256.8516 - accuracy: 0.5187\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 39177.5234 - accuracy: 0.4549\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 45512.7305 - accuracy: 0.5451\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 71082.3047 - accuracy: 0.4615\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 64931.7461 - accuracy: 0.5121\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 84741.9922 - accuracy: 0.4615\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 159771.6562 - accuracy: 0.4879\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 47766.0625 - accuracy: 0.5560\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 98313.0312 - accuracy: 0.5033\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 47266.2109 - accuracy: 0.5209\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 13851.5234 - accuracy: 0.4747\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 61776.8320 - accuracy: 0.5121\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 59458.6758 - accuracy: 0.4571\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 20160.2637 - accuracy: 0.4879\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 18347.7422 - accuracy: 0.6242\n",
            "Accuracy: 62.42\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.96      0.76        71\n",
            "           1       0.40      0.05      0.08        43\n",
            "\n",
            "    accuracy                           0.61       114\n",
            "   macro avg       0.51      0.50      0.42       114\n",
            "weighted avg       0.54      0.61      0.50       114\n",
            "\n",
            "Confusion matrix\n",
            "[[68  3]\n",
            " [41  2]]\n",
            "Accuracy score\n",
            "0.6140350877192983\n",
            "************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Models trained'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymgC-W_zXxSi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}